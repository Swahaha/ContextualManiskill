nohup: ignoring input
/home/swarajh/miniconda3/envs/hyper/lib/python3.9/site-packages/torch/nn/modules/linear.py:125: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:180.)
  return F.linear(input, self.weight, self.bias)
Initializing ContextualPandaStick...
Initializing ContextualPandaStick...
Saving eval videos to runs/ContextualPushT-v1__Contextual_hyperppo__1__1747283748/videos
Running training
Initializing ContextualPandaStick...
####
args.num_iterations=9765 args.num_envs=2048 args.num_eval_envs=8
args.minibatch_size=3200 args.batch_size=102400 args.update_epochs=8
####
Epoch: 1, global_step=0
Sampling new architecture
Evaluating
Initializing ContextualPandaStick...
Initializing ContextualPandaStick...
Evaluated 400 steps resulting in 8 episodes
Total reward during evaluation: 45.37182641029358
/home/swarajh/miniconda3/envs/hyper/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.
  return _methods._mean(a, axis=axis, dtype=dtype,
/home/swarajh/miniconda3/envs/hyper/lib/python3.9/site-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)
eval_success_once_mean=0.0
eval_return_mean=5.671478271484375
eval_episode_len_mean=50.0
eval_reward_mean=0.11342956125736237
eval_success_at_end_mean=0.0
model saved to runs/ContextualPushT-v1__Contextual_hyperppo__1__1747283748/ckpt_1.pt
SPS: 1731, pg_loss=0.0243, v_loss=0.1993
Epoch: 2, global_step=102400
Sampling new architecture
SPS: 1935, pg_loss=0.0178, v_loss=0.1662
Epoch: 3, global_step=204800
Sampling new architecture
SPS: 2043, pg_loss=0.0104, v_loss=0.1569
Epoch: 4, global_step=307200
Sampling new architecture
SPS: 2084, pg_loss=0.0067, v_loss=0.1289
Epoch: 5, global_step=409600
Sampling new architecture
SPS: 2100, pg_loss=0.0088, v_loss=0.1244
Epoch: 6, global_step=512000
Sampling new architecture
SPS: 2111, pg_loss=0.0098, v_loss=0.1053
Epoch: 7, global_step=614400
Sampling new architecture
SPS: 2122, pg_loss=0.0018, v_loss=0.1064
Epoch: 8, global_step=716800
Sampling new architecture
SPS: 2138, pg_loss=0.0288, v_loss=0.0854
Epoch: 9, global_step=819200
Sampling new architecture
SPS: 2168, pg_loss=0.0053, v_loss=0.0751
Epoch: 10, global_step=921600
Sampling new architecture
SPS: 2167, pg_loss=0.0101, v_loss=0.0687
Epoch: 11, global_step=1024000
Sampling new architecture
SPS: 2171, pg_loss=0.0119, v_loss=0.0559
Epoch: 12, global_step=1126400
Sampling new architecture
SPS: 2173, pg_loss=0.0172, v_loss=0.0550
Epoch: 13, global_step=1228800
Sampling new architecture
SPS: 2170, pg_loss=0.0111, v_loss=0.0533
Epoch: 14, global_step=1331200
Sampling new architecture
SPS: 2180, pg_loss=0.0238, v_loss=0.0482
Epoch: 15, global_step=1433600
Sampling new architecture
SPS: 2180, pg_loss=0.0269, v_loss=0.0442
Epoch: 16, global_step=1536000
Sampling new architecture
SPS: 2182, pg_loss=0.0270, v_loss=0.0406
Epoch: 17, global_step=1638400
Sampling new architecture
SPS: 2188, pg_loss=0.0346, v_loss=0.0430
Epoch: 18, global_step=1740800
Sampling new architecture
SPS: 2188, pg_loss=0.0320, v_loss=0.0409
Epoch: 19, global_step=1843200
Sampling new architecture
SPS: 2191, pg_loss=0.0250, v_loss=0.0409
Epoch: 20, global_step=1945600
Sampling new architecture
SPS: 2191, pg_loss=0.0184, v_loss=0.0515
Epoch: 21, global_step=2048000
Sampling new architecture
SPS: 2192, pg_loss=0.0118, v_loss=0.0451
Epoch: 22, global_step=2150400
Sampling new architecture
SPS: 2193, pg_loss=0.0187, v_loss=0.0708
Epoch: 23, global_step=2252800
Sampling new architecture
SPS: 2189, pg_loss=0.0316, v_loss=0.0658
Epoch: 24, global_step=2355200
Sampling new architecture
SPS: 2187, pg_loss=0.0227, v_loss=0.0704
Epoch: 25, global_step=2457600
Sampling new architecture
SPS: 2189, pg_loss=0.0185, v_loss=0.0618
Epoch: 26, global_step=2560000
Sampling new architecture
SPS: 2189, pg_loss=0.0214, v_loss=0.0776
Epoch: 27, global_step=2662400
Sampling new architecture
SPS: 2188, pg_loss=0.0318, v_loss=0.0710
Epoch: 28, global_step=2764800
Sampling new architecture
SPS: 2189, pg_loss=0.0143, v_loss=0.0951
Epoch: 29, global_step=2867200
Sampling new architecture
SPS: 2187, pg_loss=0.0225, v_loss=0.0955
Epoch: 30, global_step=2969600
Sampling new architecture
SPS: 2190, pg_loss=0.0166, v_loss=0.1132
Epoch: 31, global_step=3072000
Sampling new architecture
SPS: 2188, pg_loss=0.0261, v_loss=0.0999
Epoch: 32, global_step=3174400
Sampling new architecture
SPS: 2184, pg_loss=0.0281, v_loss=0.1111
Epoch: 33, global_step=3276800
Sampling new architecture
SPS: 2184, pg_loss=0.0188, v_loss=0.1292
Epoch: 34, global_step=3379200
Sampling new architecture
SPS: 2184, pg_loss=0.0148, v_loss=0.1505
Epoch: 35, global_step=3481600
Sampling new architecture
SPS: 2182, pg_loss=0.0159, v_loss=0.1787
Epoch: 36, global_step=3584000
Sampling new architecture
SPS: 2180, pg_loss=0.0186, v_loss=0.1358
Epoch: 37, global_step=3686400
Sampling new architecture
SPS: 2177, pg_loss=0.0175, v_loss=0.1554
Epoch: 38, global_step=3788800
Sampling new architecture
SPS: 2176, pg_loss=0.0149, v_loss=0.1736
Epoch: 39, global_step=3891200
Sampling new architecture
SPS: 2176, pg_loss=0.0153, v_loss=0.1521
Epoch: 40, global_step=3993600
Sampling new architecture
SPS: 2173, pg_loss=0.0188, v_loss=0.1466
Epoch: 41, global_step=4096000
Sampling new architecture
SPS: 2171, pg_loss=0.0114, v_loss=0.1590
Epoch: 42, global_step=4198400
Sampling new architecture
SPS: 2170, pg_loss=0.0187, v_loss=0.2048
Epoch: 43, global_step=4300800
Sampling new architecture
SPS: 2169, pg_loss=0.0117, v_loss=0.2595
Epoch: 44, global_step=4403200
Sampling new architecture
SPS: 2168, pg_loss=0.0207, v_loss=0.2166
Epoch: 45, global_step=4505600
Sampling new architecture
SPS: 2168, pg_loss=0.0128, v_loss=0.2771
Epoch: 46, global_step=4608000
Sampling new architecture
SPS: 2167, pg_loss=0.0199, v_loss=0.1812
Epoch: 47, global_step=4710400
Sampling new architecture
SPS: 2166, pg_loss=0.0164, v_loss=0.1502
Epoch: 48, global_step=4812800
Sampling new architecture
SPS: 2166, pg_loss=0.0133, v_loss=0.2010
Epoch: 49, global_step=4915200
Sampling new architecture
SPS: 2163, pg_loss=0.0210, v_loss=0.2119
Epoch: 50, global_step=5017600
Sampling new architecture
SPS: 2159, pg_loss=0.0197, v_loss=0.2095
Epoch: 51, global_step=5120000
Sampling new architecture
Evaluating
Initializing ContextualPandaStick...
Initializing ContextualPandaStick...
Evaluated 400 steps resulting in 8 episodes
Total reward during evaluation: 64.77580738067627
eval_success_once_mean=0.0
eval_return_mean=8.096975326538086
eval_episode_len_mean=50.0
eval_reward_mean=0.16193951666355133
eval_success_at_end_mean=0.0
model saved to runs/ContextualPushT-v1__Contextual_hyperppo__1__1747283748/ckpt_51.pt
SPS: 2149, pg_loss=0.0136, v_loss=0.2194
Epoch: 52, global_step=5222400
Sampling new architecture
SPS: 2148, pg_loss=0.0116, v_loss=0.2414
Epoch: 53, global_step=5324800
Sampling new architecture
SPS: 2147, pg_loss=0.0186, v_loss=0.2760
Epoch: 54, global_step=5427200
Sampling new architecture
SPS: 2145, pg_loss=0.0185, v_loss=0.2122
Epoch: 55, global_step=5529600
Sampling new architecture
SPS: 2145, pg_loss=0.0228, v_loss=0.2364
Epoch: 56, global_step=5632000
Sampling new architecture
SPS: 2145, pg_loss=0.0136, v_loss=0.2069
Epoch: 57, global_step=5734400
Sampling new architecture
SPS: 2143, pg_loss=0.0226, v_loss=0.2259
Epoch: 58, global_step=5836800
Sampling new architecture
SPS: 2142, pg_loss=0.0245, v_loss=0.2122
Epoch: 59, global_step=5939200
Sampling new architecture
SPS: 2140, pg_loss=0.0195, v_loss=0.2090
Epoch: 60, global_step=6041600
Sampling new architecture
SPS: 2139, pg_loss=0.0224, v_loss=0.2657
Epoch: 61, global_step=6144000
Sampling new architecture
SPS: 2137, pg_loss=0.0151, v_loss=0.3663
Epoch: 62, global_step=6246400
Sampling new architecture
SPS: 2136, pg_loss=0.0136, v_loss=0.2253
Epoch: 63, global_step=6348800
Sampling new architecture
SPS: 2136, pg_loss=0.0126, v_loss=0.2835
Epoch: 64, global_step=6451200
Sampling new architecture
SPS: 2134, pg_loss=0.0160, v_loss=0.2218
Epoch: 65, global_step=6553600
Sampling new architecture
SPS: 2134, pg_loss=0.0211, v_loss=0.1925
Epoch: 66, global_step=6656000
Sampling new architecture
SPS: 2134, pg_loss=0.0187, v_loss=0.2543
Epoch: 67, global_step=6758400
Sampling new architecture
SPS: 2135, pg_loss=0.0219, v_loss=0.3093
Epoch: 68, global_step=6860800
Sampling new architecture
SPS: 2134, pg_loss=0.0346, v_loss=0.2149
Epoch: 69, global_step=6963200
Sampling new architecture
SPS: 2135, pg_loss=0.0172, v_loss=0.2609
Epoch: 70, global_step=7065600
Sampling new architecture
SPS: 2135, pg_loss=0.0214, v_loss=0.1530
Epoch: 71, global_step=7168000
Sampling new architecture
SPS: 2134, pg_loss=0.0295, v_loss=0.1802
Epoch: 72, global_step=7270400
Sampling new architecture
SPS: 2133, pg_loss=0.0200, v_loss=0.2862
Epoch: 73, global_step=7372800
Sampling new architecture
SPS: 2134, pg_loss=0.0223, v_loss=0.2662
Epoch: 74, global_step=7475200
Sampling new architecture
SPS: 2135, pg_loss=0.0199, v_loss=0.2393
Epoch: 75, global_step=7577600
Sampling new architecture
SPS: 2135, pg_loss=0.0272, v_loss=0.2628
Epoch: 76, global_step=7680000
Sampling new architecture
SPS: 2134, pg_loss=0.0250, v_loss=0.3033
Epoch: 77, global_step=7782400
Sampling new architecture
SPS: 2135, pg_loss=0.0227, v_loss=0.2722
Epoch: 78, global_step=7884800
Sampling new architecture
SPS: 2135, pg_loss=0.0296, v_loss=0.2158
Epoch: 79, global_step=7987200
Sampling new architecture
SPS: 2135, pg_loss=0.0224, v_loss=0.2515
Epoch: 80, global_step=8089600
Sampling new architecture
SPS: 2135, pg_loss=0.0318, v_loss=0.2777
Epoch: 81, global_step=8192000
Sampling new architecture
SPS: 2135, pg_loss=0.0219, v_loss=0.2563
Epoch: 82, global_step=8294400
Sampling new architecture
SPS: 2135, pg_loss=0.0361, v_loss=0.2112
Epoch: 83, global_step=8396800
Sampling new architecture
SPS: 2135, pg_loss=0.0313, v_loss=0.1981
Epoch: 84, global_step=8499200
Sampling new architecture
SPS: 2135, pg_loss=0.0366, v_loss=0.1931
Epoch: 85, global_step=8601600
Sampling new architecture
SPS: 2135, pg_loss=0.0301, v_loss=0.1562
Epoch: 86, global_step=8704000
Sampling new architecture
SPS: 2135, pg_loss=0.0246, v_loss=0.1771
Epoch: 87, global_step=8806400
Sampling new architecture
SPS: 2137, pg_loss=0.0233, v_loss=0.1637
Epoch: 88, global_step=8908800
Sampling new architecture
SPS: 2137, pg_loss=0.0202, v_loss=0.1813
Epoch: 89, global_step=9011200
Sampling new architecture
SPS: 2137, pg_loss=0.0251, v_loss=0.2382
Epoch: 90, global_step=9113600
Sampling new architecture
SPS: 2136, pg_loss=0.0205, v_loss=0.2449
Epoch: 91, global_step=9216000
Sampling new architecture
SPS: 2137, pg_loss=0.0296, v_loss=0.1862
Epoch: 92, global_step=9318400
Sampling new architecture
SPS: 2137, pg_loss=0.0122, v_loss=0.1560
Epoch: 93, global_step=9420800
Sampling new architecture
SPS: 2137, pg_loss=0.0155, v_loss=0.1622
Epoch: 94, global_step=9523200
Sampling new architecture
SPS: 2136, pg_loss=0.0259, v_loss=0.1932
Epoch: 95, global_step=9625600
Sampling new architecture
SPS: 2136, pg_loss=0.0219, v_loss=0.2141
Epoch: 96, global_step=9728000
Sampling new architecture
SPS: 2136, pg_loss=0.0240, v_loss=0.1579
Epoch: 97, global_step=9830400
Sampling new architecture
SPS: 2136, pg_loss=0.0258, v_loss=0.1303
Epoch: 98, global_step=9932800
Sampling new architecture
SPS: 2137, pg_loss=0.0229, v_loss=0.1600
Epoch: 99, global_step=10035200
Sampling new architecture
SPS: 2138, pg_loss=0.0172, v_loss=0.2041
Epoch: 100, global_step=10137600
Sampling new architecture
SPS: 2137, pg_loss=0.0113, v_loss=0.2151
Epoch: 101, global_step=10240000
Sampling new architecture
Evaluating
Initializing ContextualPandaStick...
Initializing ContextualPandaStick...
Evaluated 400 steps resulting in 8 episodes
Total reward during evaluation: 39.74965703487396
eval_success_once_mean=0.0
eval_return_mean=4.968707084655762
eval_episode_len_mean=50.0
eval_reward_mean=0.09937414526939392
eval_success_at_end_mean=0.0
model saved to runs/ContextualPushT-v1__Contextual_hyperppo__1__1747283748/ckpt_101.pt
SPS: 2131, pg_loss=0.0302, v_loss=0.2616
Epoch: 102, global_step=10342400
Sampling new architecture
SPS: 2132, pg_loss=0.0164, v_loss=0.2362
Epoch: 103, global_step=10444800
Sampling new architecture
SPS: 2132, pg_loss=0.0202, v_loss=0.2471
Epoch: 104, global_step=10547200
Sampling new architecture
SPS: 2132, pg_loss=0.0201, v_loss=0.2304
Epoch: 105, global_step=10649600
Sampling new architecture
SPS: 2134, pg_loss=0.0158, v_loss=0.2100
Epoch: 106, global_step=10752000
Sampling new architecture
SPS: 2135, pg_loss=0.0201, v_loss=0.2359
Epoch: 107, global_step=10854400
Sampling new architecture
SPS: 2136, pg_loss=0.0268, v_loss=0.2546
Epoch: 108, global_step=10956800
Sampling new architecture
SPS: 2136, pg_loss=0.0208, v_loss=0.1999
Epoch: 109, global_step=11059200
Sampling new architecture
SPS: 2136, pg_loss=0.0239, v_loss=0.2182
Epoch: 110, global_step=11161600
Sampling new architecture
SPS: 2135, pg_loss=0.0253, v_loss=0.2368
Epoch: 111, global_step=11264000
Sampling new architecture
SPS: 2134, pg_loss=0.0240, v_loss=0.2619
Epoch: 112, global_step=11366400
Sampling new architecture
SPS: 2136, pg_loss=0.0252, v_loss=0.1793
Epoch: 113, global_step=11468800
Sampling new architecture
SPS: 2135, pg_loss=0.0185, v_loss=0.2809
Epoch: 114, global_step=11571200
Sampling new architecture
SPS: 2135, pg_loss=0.0226, v_loss=0.1922
Epoch: 115, global_step=11673600
Sampling new architecture
SPS: 2135, pg_loss=0.0183, v_loss=0.2201
Epoch: 116, global_step=11776000
Sampling new architecture
SPS: 2136, pg_loss=0.0242, v_loss=0.2024
Epoch: 117, global_step=11878400
Sampling new architecture
SPS: 2136, pg_loss=0.0333, v_loss=0.1963
Epoch: 118, global_step=11980800
Sampling new architecture
SPS: 2135, pg_loss=0.0210, v_loss=0.2006
Epoch: 119, global_step=12083200
Sampling new architecture
SPS: 2135, pg_loss=0.0229, v_loss=0.1823
Epoch: 120, global_step=12185600
Sampling new architecture
SPS: 2136, pg_loss=0.0290, v_loss=0.1879
Epoch: 121, global_step=12288000
Sampling new architecture
SPS: 2136, pg_loss=0.0220, v_loss=0.1466
Epoch: 122, global_step=12390400
Sampling new architecture
SPS: 2136, pg_loss=0.0210, v_loss=0.2187
Epoch: 123, global_step=12492800
Sampling new architecture
SPS: 2135, pg_loss=0.0279, v_loss=0.1783
Epoch: 124, global_step=12595200
Sampling new architecture
SPS: 2136, pg_loss=0.0264, v_loss=0.1692
Epoch: 125, global_step=12697600
Sampling new architecture
SPS: 2135, pg_loss=0.0261, v_loss=0.1635
Epoch: 126, global_step=12800000
Sampling new architecture
SPS: 2134, pg_loss=0.0280, v_loss=0.1688
Epoch: 127, global_step=12902400
Sampling new architecture
SPS: 2135, pg_loss=0.0241, v_loss=0.1693
Epoch: 128, global_step=13004800
Sampling new architecture
SPS: 2135, pg_loss=0.0237, v_loss=0.2126
Epoch: 129, global_step=13107200
Sampling new architecture
SPS: 2134, pg_loss=0.0307, v_loss=0.2194
Epoch: 130, global_step=13209600
Sampling new architecture
SPS: 2135, pg_loss=0.0255, v_loss=0.1937
Epoch: 131, global_step=13312000
Sampling new architecture
SPS: 2135, pg_loss=0.0264, v_loss=0.1908
Epoch: 132, global_step=13414400
Sampling new architecture
SPS: 2135, pg_loss=0.0258, v_loss=0.2588
Epoch: 133, global_step=13516800
Sampling new architecture
SPS: 2135, pg_loss=0.0170, v_loss=0.1660
Epoch: 134, global_step=13619200
Sampling new architecture
SPS: 2134, pg_loss=0.0344, v_loss=0.1884
Epoch: 135, global_step=13721600
Sampling new architecture
SPS: 2134, pg_loss=0.0292, v_loss=0.1885
Epoch: 136, global_step=13824000
Sampling new architecture
SPS: 2133, pg_loss=0.0215, v_loss=0.1620
Epoch: 137, global_step=13926400
Sampling new architecture
SPS: 2133, pg_loss=0.0269, v_loss=0.1624
Epoch: 138, global_step=14028800
Sampling new architecture
SPS: 2132, pg_loss=0.0298, v_loss=0.1588
Epoch: 139, global_step=14131200
Sampling new architecture
SPS: 2132, pg_loss=0.0379, v_loss=0.1792
Epoch: 140, global_step=14233600
Sampling new architecture
SPS: 2132, pg_loss=0.0309, v_loss=0.1991
Epoch: 141, global_step=14336000
Sampling new architecture
SPS: 2132, pg_loss=0.0192, v_loss=0.1786
Epoch: 142, global_step=14438400
Sampling new architecture
SPS: 2132, pg_loss=0.0410, v_loss=0.1912
Epoch: 143, global_step=14540800
Sampling new architecture
SPS: 2132, pg_loss=0.0223, v_loss=0.2166
Epoch: 144, global_step=14643200
Sampling new architecture
SPS: 2132, pg_loss=0.0239, v_loss=0.2084
Epoch: 145, global_step=14745600
Sampling new architecture
SPS: 2133, pg_loss=0.0341, v_loss=0.2060
Epoch: 146, global_step=14848000
Sampling new architecture
SPS: 2134, pg_loss=0.0240, v_loss=0.2052
Epoch: 147, global_step=14950400
Sampling new architecture
SPS: 2135, pg_loss=0.0234, v_loss=0.1820
Epoch: 148, global_step=15052800
Sampling new architecture
SPS: 2135, pg_loss=0.0273, v_loss=0.2010
Epoch: 149, global_step=15155200
Sampling new architecture
SPS: 2136, pg_loss=0.0264, v_loss=0.2363
Epoch: 150, global_step=15257600
Sampling new architecture
SPS: 2136, pg_loss=0.0195, v_loss=0.1950
Epoch: 151, global_step=15360000
Sampling new architecture
Evaluating
Initializing ContextualPandaStick...
Initializing ContextualPandaStick...
Evaluated 400 steps resulting in 8 episodes
Total reward during evaluation: 53.27849197387695
eval_success_once_mean=0.0
eval_return_mean=6.659811973571777
eval_episode_len_mean=50.0
eval_reward_mean=0.13319623470306396
eval_success_at_end_mean=0.0
model saved to runs/ContextualPushT-v1__Contextual_hyperppo__1__1747283748/ckpt_151.pt
SPS: 2133, pg_loss=0.0380, v_loss=0.1842
Epoch: 152, global_step=15462400
Sampling new architecture
SPS: 2132, pg_loss=0.0192, v_loss=0.1961
Epoch: 153, global_step=15564800
Sampling new architecture
SPS: 2132, pg_loss=0.0197, v_loss=0.1774
Epoch: 154, global_step=15667200
Sampling new architecture
SPS: 2132, pg_loss=0.0199, v_loss=0.1929
Epoch: 155, global_step=15769600
Sampling new architecture
SPS: 2132, pg_loss=0.0278, v_loss=0.1551
Epoch: 156, global_step=15872000
Sampling new architecture
SPS: 2132, pg_loss=0.0374, v_loss=0.1764
Epoch: 157, global_step=15974400
Sampling new architecture
SPS: 2131, pg_loss=0.0217, v_loss=0.2048
Epoch: 158, global_step=16076800
Sampling new architecture
SPS: 2131, pg_loss=0.0141, v_loss=0.1871
Epoch: 159, global_step=16179200
Sampling new architecture
SPS: 2133, pg_loss=0.0156, v_loss=0.1623
Epoch: 160, global_step=16281600
Sampling new architecture
SPS: 2136, pg_loss=0.0301, v_loss=0.1762
Epoch: 161, global_step=16384000
Sampling new architecture
SPS: 2139, pg_loss=0.0324, v_loss=0.1667
Epoch: 162, global_step=16486400
Sampling new architecture
SPS: 2141, pg_loss=0.0203, v_loss=0.1601
Epoch: 163, global_step=16588800
Sampling new architecture
SPS: 2144, pg_loss=0.0233, v_loss=0.1544
Epoch: 164, global_step=16691200
Sampling new architecture
SPS: 2147, pg_loss=0.0415, v_loss=0.1838
Epoch: 165, global_step=16793600
Sampling new architecture
SPS: 2150, pg_loss=0.0256, v_loss=0.1556
Epoch: 166, global_step=16896000
Sampling new architecture
SPS: 2152, pg_loss=0.0253, v_loss=0.2764
Epoch: 167, global_step=16998400
Sampling new architecture
SPS: 2155, pg_loss=0.0395, v_loss=0.1634
Epoch: 168, global_step=17100800
Sampling new architecture
SPS: 2158, pg_loss=0.0352, v_loss=0.1733
Epoch: 169, global_step=17203200
Sampling new architecture
SPS: 2161, pg_loss=0.0201, v_loss=0.1707
Epoch: 170, global_step=17305600
Sampling new architecture
SPS: 2164, pg_loss=0.0274, v_loss=0.1986
Epoch: 171, global_step=17408000
Sampling new architecture
SPS: 2167, pg_loss=0.0222, v_loss=0.1847
Epoch: 172, global_step=17510400
Sampling new architecture
SPS: 2169, pg_loss=0.0308, v_loss=0.1701
Epoch: 173, global_step=17612800
Sampling new architecture
SPS: 2172, pg_loss=0.0299, v_loss=0.1554
Epoch: 174, global_step=17715200
Sampling new architecture
SPS: 2174, pg_loss=0.0228, v_loss=0.1699
Epoch: 175, global_step=17817600
Sampling new architecture
SPS: 2177, pg_loss=0.0299, v_loss=0.2048
Epoch: 176, global_step=17920000
Sampling new architecture
SPS: 2180, pg_loss=0.0257, v_loss=0.2326
Epoch: 177, global_step=18022400
Sampling new architecture
SPS: 2182, pg_loss=0.0306, v_loss=0.2467
Epoch: 178, global_step=18124800
Sampling new architecture
SPS: 2185, pg_loss=0.0229, v_loss=0.1776
Epoch: 179, global_step=18227200
Sampling new architecture
SPS: 2187, pg_loss=0.0186, v_loss=0.1871
Epoch: 180, global_step=18329600
Sampling new architecture
SPS: 2189, pg_loss=0.0359, v_loss=0.1671
Epoch: 181, global_step=18432000
Sampling new architecture
SPS: 2191, pg_loss=0.0358, v_loss=0.1931
Epoch: 182, global_step=18534400
Sampling new architecture
SPS: 2194, pg_loss=0.0279, v_loss=0.1937
Epoch: 183, global_step=18636800
Sampling new architecture
SPS: 2196, pg_loss=0.0220, v_loss=0.1988
Epoch: 184, global_step=18739200
Sampling new architecture
SPS: 2199, pg_loss=0.0302, v_loss=0.2082
Epoch: 185, global_step=18841600
Sampling new architecture
SPS: 2201, pg_loss=0.0191, v_loss=0.2009
Epoch: 186, global_step=18944000
Sampling new architecture
SPS: 2205, pg_loss=0.0287, v_loss=0.1559
Epoch: 187, global_step=19046400
Sampling new architecture
SPS: 2207, pg_loss=0.0248, v_loss=0.1772
Epoch: 188, global_step=19148800
Sampling new architecture
SPS: 2209, pg_loss=0.0428, v_loss=0.2070
Epoch: 189, global_step=19251200
Sampling new architecture
SPS: 2211, pg_loss=0.0218, v_loss=0.2217
Epoch: 190, global_step=19353600
Sampling new architecture
SPS: 2213, pg_loss=0.0248, v_loss=0.2076
Epoch: 191, global_step=19456000
Sampling new architecture
SPS: 2215, pg_loss=0.0318, v_loss=0.1971
Epoch: 192, global_step=19558400
Sampling new architecture
SPS: 2217, pg_loss=0.0239, v_loss=0.2278
Epoch: 193, global_step=19660800
Sampling new architecture
SPS: 2219, pg_loss=0.0304, v_loss=0.2320
Epoch: 194, global_step=19763200
Sampling new architecture
SPS: 2220, pg_loss=0.0387, v_loss=0.2110
Epoch: 195, global_step=19865600
Sampling new architecture
SPS: 2229, pg_loss=0.0241, v_loss=0.3214
Epoch: 196, global_step=19968000
Sampling new architecture
SPS: 2231, pg_loss=0.0249, v_loss=0.2167
Epoch: 197, global_step=20070400
Sampling new architecture
SPS: 2232, pg_loss=0.0270, v_loss=0.2090
Epoch: 198, global_step=20172800
Sampling new architecture
SPS: 2234, pg_loss=0.0200, v_loss=0.1712
Epoch: 199, global_step=20275200
Sampling new architecture
SPS: 2235, pg_loss=0.0212, v_loss=0.1901
Epoch: 200, global_step=20377600
Sampling new architecture
SPS: 2237, pg_loss=0.0352, v_loss=0.1642
Epoch: 201, global_step=20480000
Sampling new architecture
Evaluating
Initializing ContextualPandaStick...
Initializing ContextualPandaStick...
Evaluated 400 steps resulting in 8 episodes
Total reward during evaluation: 53.169074296951294
eval_success_once_mean=0.0
eval_return_mean=6.646134376525879
eval_episode_len_mean=50.0
eval_reward_mean=0.1329226791858673
eval_success_at_end_mean=0.0
model saved to runs/ContextualPushT-v1__Contextual_hyperppo__1__1747283748/ckpt_201.pt
SPS: 2237, pg_loss=0.0350, v_loss=0.1679
Epoch: 202, global_step=20582400
Sampling new architecture
SPS: 2238, pg_loss=0.0253, v_loss=0.1693
Epoch: 203, global_step=20684800
Sampling new architecture
SPS: 2240, pg_loss=0.0357, v_loss=0.1548
Epoch: 204, global_step=20787200
Sampling new architecture
SPS: 2241, pg_loss=0.0223, v_loss=0.1829
Epoch: 205, global_step=20889600
Sampling new architecture
SPS: 2243, pg_loss=0.0280, v_loss=0.1978
Epoch: 206, global_step=20992000
Sampling new architecture
SPS: 2245, pg_loss=0.0213, v_loss=0.1762
Epoch: 207, global_step=21094400
Sampling new architecture
SPS: 2247, pg_loss=0.0233, v_loss=0.1983
Epoch: 208, global_step=21196800
Sampling new architecture
SPS: 2248, pg_loss=0.0295, v_loss=0.1672
Epoch: 209, global_step=21299200
Sampling new architecture
SPS: 2249, pg_loss=0.0327, v_loss=0.1923
Epoch: 210, global_step=21401600
Sampling new architecture
SPS: 2251, pg_loss=0.0231, v_loss=0.2088
Epoch: 211, global_step=21504000
Sampling new architecture
SPS: 2252, pg_loss=0.0209, v_loss=0.1881
Epoch: 212, global_step=21606400
Sampling new architecture
SPS: 2254, pg_loss=0.0215, v_loss=0.2239
Epoch: 213, global_step=21708800
Sampling new architecture
SPS: 2256, pg_loss=0.0443, v_loss=0.2021
Epoch: 214, global_step=21811200
Sampling new architecture
SPS: 2258, pg_loss=0.0258, v_loss=0.1853
Epoch: 215, global_step=21913600
Sampling new architecture
SPS: 2259, pg_loss=0.0239, v_loss=0.1974
Epoch: 216, global_step=22016000
Sampling new architecture
SPS: 2261, pg_loss=0.0343, v_loss=0.1696
Epoch: 217, global_step=22118400
Sampling new architecture
SPS: 2262, pg_loss=0.0357, v_loss=0.1757
Epoch: 218, global_step=22220800
Sampling new architecture
SPS: 2263, pg_loss=0.0307, v_loss=0.1870
Epoch: 219, global_step=22323200
Sampling new architecture
SPS: 2264, pg_loss=0.0174, v_loss=0.1800
Epoch: 220, global_step=22425600
Sampling new architecture
SPS: 2266, pg_loss=0.0201, v_loss=0.1768
Epoch: 221, global_step=22528000
Sampling new architecture
SPS: 2268, pg_loss=0.0287, v_loss=0.1661
Epoch: 222, global_step=22630400
Sampling new architecture
SPS: 2270, pg_loss=0.0307, v_loss=0.2164
Epoch: 223, global_step=22732800
Sampling new architecture
SPS: 2272, pg_loss=0.0221, v_loss=0.1797
Epoch: 224, global_step=22835200
Sampling new architecture
SPS: 2273, pg_loss=0.0315, v_loss=0.1653
Epoch: 225, global_step=22937600
Sampling new architecture
SPS: 2275, pg_loss=0.0248, v_loss=0.1718
Epoch: 226, global_step=23040000
Sampling new architecture
SPS: 2276, pg_loss=0.0306, v_loss=0.1872
Epoch: 227, global_step=23142400
Sampling new architecture
SPS: 2278, pg_loss=0.0195, v_loss=0.1801
Epoch: 228, global_step=23244800
Sampling new architecture
SPS: 2281, pg_loss=0.0272, v_loss=0.1944
Epoch: 229, global_step=23347200
Sampling new architecture
SPS: 2282, pg_loss=0.0202, v_loss=0.1618
Epoch: 230, global_step=23449600
Sampling new architecture
SPS: 2284, pg_loss=0.0365, v_loss=0.1652
Epoch: 231, global_step=23552000
Sampling new architecture
SPS: 2285, pg_loss=0.0290, v_loss=0.1824
Epoch: 232, global_step=23654400
Sampling new architecture
SPS: 2287, pg_loss=0.0264, v_loss=0.1370
Epoch: 233, global_step=23756800
Sampling new architecture
SPS: 2289, pg_loss=0.0201, v_loss=0.2288
Epoch: 234, global_step=23859200
Sampling new architecture
SPS: 2290, pg_loss=0.0288, v_loss=0.1992
Epoch: 235, global_step=23961600
Sampling new architecture
SPS: 2291, pg_loss=0.0292, v_loss=0.1471
Epoch: 236, global_step=24064000
Sampling new architecture
SPS: 2292, pg_loss=0.0281, v_loss=0.1636
Epoch: 237, global_step=24166400
Sampling new architecture
SPS: 2294, pg_loss=0.0319, v_loss=0.2000
Epoch: 238, global_step=24268800
Sampling new architecture
SPS: 2296, pg_loss=0.0221, v_loss=0.1908
Epoch: 239, global_step=24371200
Sampling new architecture
SPS: 2297, pg_loss=0.0275, v_loss=0.1570
Epoch: 240, global_step=24473600
Sampling new architecture
SPS: 2298, pg_loss=0.0230, v_loss=0.1486
Epoch: 241, global_step=24576000
Sampling new architecture
SPS: 2300, pg_loss=0.0190, v_loss=0.2063
Epoch: 242, global_step=24678400
Sampling new architecture
SPS: 2301, pg_loss=0.0305, v_loss=0.1765
Epoch: 243, global_step=24780800
Sampling new architecture
SPS: 2303, pg_loss=0.0215, v_loss=0.1929
Epoch: 244, global_step=24883200
Sampling new architecture
SPS: 2304, pg_loss=0.0226, v_loss=0.2259
Epoch: 245, global_step=24985600
Sampling new architecture
SPS: 2305, pg_loss=0.0259, v_loss=0.1360
Epoch: 246, global_step=25088000
Sampling new architecture
SPS: 2306, pg_loss=0.0259, v_loss=0.1488
Epoch: 247, global_step=25190400
Sampling new architecture
SPS: 2307, pg_loss=0.0310, v_loss=0.1303
Epoch: 248, global_step=25292800
Sampling new architecture
SPS: 2309, pg_loss=0.0197, v_loss=0.1560
Epoch: 249, global_step=25395200
Sampling new architecture
SPS: 2310, pg_loss=0.0263, v_loss=0.1895
Epoch: 250, global_step=25497600
Sampling new architecture
SPS: 2311, pg_loss=0.0157, v_loss=0.1460
Epoch: 251, global_step=25600000
Sampling new architecture
Evaluating
Initializing ContextualPandaStick...
Initializing ContextualPandaStick...
Evaluated 400 steps resulting in 8 episodes
Total reward during evaluation: 51.66398286819458
eval_success_once_mean=0.0
eval_return_mean=6.457997798919678
eval_episode_len_mean=50.0
eval_reward_mean=0.12915995717048645
eval_success_at_end_mean=0.0
model saved to runs/ContextualPushT-v1__Contextual_hyperppo__1__1747283748/ckpt_251.pt
SPS: 2312, pg_loss=0.0322, v_loss=0.1807
Epoch: 252, global_step=25702400
Sampling new architecture
SPS: 2313, pg_loss=0.0266, v_loss=0.2098
Epoch: 253, global_step=25804800
Sampling new architecture
SPS: 2314, pg_loss=0.0303, v_loss=0.1686
Epoch: 254, global_step=25907200
Sampling new architecture
SPS: 2316, pg_loss=0.0255, v_loss=0.1816
Epoch: 255, global_step=26009600
Sampling new architecture
SPS: 2317, pg_loss=0.0207, v_loss=0.1587
Epoch: 256, global_step=26112000
Sampling new architecture
SPS: 2318, pg_loss=0.0270, v_loss=0.1539
Epoch: 257, global_step=26214400
Sampling new architecture
SPS: 2319, pg_loss=0.0307, v_loss=0.1673
Epoch: 258, global_step=26316800
Sampling new architecture
SPS: 2320, pg_loss=0.0329, v_loss=0.1557
Epoch: 259, global_step=26419200
Sampling new architecture
SPS: 2321, pg_loss=0.0297, v_loss=0.1691
Epoch: 260, global_step=26521600
Sampling new architecture
SPS: 2323, pg_loss=0.0355, v_loss=0.1807
Epoch: 261, global_step=26624000
Sampling new architecture
SPS: 2324, pg_loss=0.0288, v_loss=0.1691
Epoch: 262, global_step=26726400
Sampling new architecture
SPS: 2325, pg_loss=0.0332, v_loss=0.1908
Epoch: 263, global_step=26828800
Sampling new architecture
SPS: 2326, pg_loss=0.0284, v_loss=0.1579
Epoch: 264, global_step=26931200
Sampling new architecture
SPS: 2328, pg_loss=0.0276, v_loss=0.1706
Epoch: 265, global_step=27033600
Sampling new architecture
SPS: 2329, pg_loss=0.0190, v_loss=0.1535
Epoch: 266, global_step=27136000
Sampling new architecture
SPS: 2330, pg_loss=0.0256, v_loss=0.1819
Epoch: 267, global_step=27238400
Sampling new architecture
SPS: 2331, pg_loss=0.0280, v_loss=0.1883
Epoch: 268, global_step=27340800
Sampling new architecture
SPS: 2333, pg_loss=0.0340, v_loss=0.1906
Epoch: 269, global_step=27443200
Sampling new architecture
SPS: 2334, pg_loss=0.0170, v_loss=0.1551
Epoch: 270, global_step=27545600
Sampling new architecture
SPS: 2336, pg_loss=0.0213, v_loss=0.1782
Epoch: 271, global_step=27648000
Sampling new architecture
SPS: 2337, pg_loss=0.0255, v_loss=0.1783
Epoch: 272, global_step=27750400
Sampling new architecture
SPS: 2338, pg_loss=0.0278, v_loss=0.1848
Epoch: 273, global_step=27852800
Sampling new architecture
SPS: 2339, pg_loss=0.0213, v_loss=0.1744
Epoch: 274, global_step=27955200
Sampling new architecture
SPS: 2340, pg_loss=0.0348, v_loss=0.2269
Epoch: 275, global_step=28057600
Sampling new architecture
SPS: 2342, pg_loss=0.0246, v_loss=0.1692
Epoch: 276, global_step=28160000
Sampling new architecture
SPS: 2343, pg_loss=0.0249, v_loss=0.1816
Epoch: 277, global_step=28262400
Sampling new architecture
SPS: 2345, pg_loss=0.0299, v_loss=0.1840
Epoch: 278, global_step=28364800
Sampling new architecture
SPS: 2346, pg_loss=0.0345, v_loss=0.1366
Epoch: 279, global_step=28467200
Sampling new architecture
SPS: 2347, pg_loss=0.0206, v_loss=0.1321
Epoch: 280, global_step=28569600
Sampling new architecture
SPS: 2348, pg_loss=0.0384, v_loss=0.1546
Epoch: 281, global_step=28672000
Sampling new architecture
SPS: 2349, pg_loss=0.0281, v_loss=0.1593
Epoch: 282, global_step=28774400
Sampling new architecture
SPS: 2350, pg_loss=0.0298, v_loss=0.2062
Epoch: 283, global_step=28876800
Sampling new architecture
SPS: 2351, pg_loss=0.0324, v_loss=0.1725
Epoch: 284, global_step=28979200
Sampling new architecture
SPS: 2352, pg_loss=0.0402, v_loss=0.1813
Epoch: 285, global_step=29081600
Sampling new architecture
SPS: 2353, pg_loss=0.0216, v_loss=0.1900
Epoch: 286, global_step=29184000
Sampling new architecture
SPS: 2354, pg_loss=0.0162, v_loss=0.1861
Epoch: 287, global_step=29286400
Sampling new architecture
SPS: 2355, pg_loss=0.0277, v_loss=0.1807
Epoch: 288, global_step=29388800
Sampling new architecture
SPS: 2356, pg_loss=0.0350, v_loss=0.2092
Epoch: 289, global_step=29491200
Sampling new architecture
SPS: 2357, pg_loss=0.0295, v_loss=0.2557
Epoch: 290, global_step=29593600
Sampling new architecture
SPS: 2359, pg_loss=0.0222, v_loss=0.2763
Epoch: 291, global_step=29696000
Sampling new architecture
SPS: 2360, pg_loss=0.0357, v_loss=0.2191
Epoch: 292, global_step=29798400
Sampling new architecture
SPS: 2361, pg_loss=0.0478, v_loss=0.2562
Epoch: 293, global_step=29900800
Sampling new architecture
SPS: 2362, pg_loss=0.0295, v_loss=0.2428
Epoch: 294, global_step=30003200
Sampling new architecture
SPS: 2363, pg_loss=0.0122, v_loss=0.2101
Epoch: 295, global_step=30105600
Sampling new architecture
SPS: 2364, pg_loss=0.0337, v_loss=0.2291
Epoch: 296, global_step=30208000
Sampling new architecture
SPS: 2365, pg_loss=0.0422, v_loss=0.2012
Epoch: 297, global_step=30310400
Sampling new architecture
SPS: 2367, pg_loss=0.0353, v_loss=0.2420
Epoch: 298, global_step=30412800
Sampling new architecture
SPS: 2368, pg_loss=0.0351, v_loss=0.2266
Epoch: 299, global_step=30515200
Sampling new architecture
SPS: 2368, pg_loss=0.0382, v_loss=0.2320
Epoch: 300, global_step=30617600
Sampling new architecture
SPS: 2369, pg_loss=0.0458, v_loss=0.2247
Epoch: 301, global_step=30720000
Sampling new architecture
Evaluating
Initializing ContextualPandaStick...
Initializing ContextualPandaStick...
Evaluated 400 steps resulting in 8 episodes
Total reward during evaluation: 32.998018860816956
eval_success_once_mean=0.0
eval_return_mean=4.124752521514893
eval_episode_len_mean=50.0
eval_reward_mean=0.08249504864215851
eval_success_at_end_mean=0.0
model saved to runs/ContextualPushT-v1__Contextual_hyperppo__1__1747283748/ckpt_301.pt
SPS: 2368, pg_loss=0.0410, v_loss=0.2115
Epoch: 302, global_step=30822400
Sampling new architecture
SPS: 2369, pg_loss=0.0287, v_loss=0.2504
Epoch: 303, global_step=30924800
Sampling new architecture
SPS: 2370, pg_loss=0.0424, v_loss=0.1869
Epoch: 304, global_step=31027200
Sampling new architecture
SPS: 2371, pg_loss=0.0483, v_loss=0.2235
Epoch: 305, global_step=31129600
Sampling new architecture
SPS: 2372, pg_loss=0.0192, v_loss=0.2349
Epoch: 306, global_step=31232000
Sampling new architecture
SPS: 2373, pg_loss=0.0256, v_loss=0.2410
Epoch: 307, global_step=31334400
Sampling new architecture
SPS: 2373, pg_loss=0.0277, v_loss=0.1960
Epoch: 308, global_step=31436800
Sampling new architecture
SPS: 2374, pg_loss=0.0411, v_loss=0.1809
Epoch: 309, global_step=31539200
Sampling new architecture
SPS: 2375, pg_loss=0.0388, v_loss=0.2404
Epoch: 310, global_step=31641600
Sampling new architecture
SPS: 2376, pg_loss=0.0267, v_loss=0.2405
Epoch: 311, global_step=31744000
Sampling new architecture
SPS: 2377, pg_loss=0.0250, v_loss=0.2242
Epoch: 312, global_step=31846400
Sampling new architecture
SPS: 2378, pg_loss=0.0285, v_loss=0.2254
Epoch: 313, global_step=31948800
Sampling new architecture
SPS: 2379, pg_loss=0.0462, v_loss=0.1947
Epoch: 314, global_step=32051200
Sampling new architecture
SPS: 2379, pg_loss=0.0444, v_loss=0.1590
Epoch: 315, global_step=32153600
Sampling new architecture
SPS: 2380, pg_loss=0.0310, v_loss=0.1603
Epoch: 316, global_step=32256000
Sampling new architecture
SPS: 2380, pg_loss=0.0359, v_loss=0.1657
Epoch: 317, global_step=32358400
Sampling new architecture
SPS: 2381, pg_loss=0.0384, v_loss=0.1606
Epoch: 318, global_step=32460800
Sampling new architecture
SPS: 2382, pg_loss=0.0293, v_loss=0.1897
Epoch: 319, global_step=32563200
Sampling new architecture
SPS: 2383, pg_loss=0.0286, v_loss=0.1481
Epoch: 320, global_step=32665600
Sampling new architecture
SPS: 2384, pg_loss=0.0366, v_loss=0.1500
Epoch: 321, global_step=32768000
Sampling new architecture
SPS: 2384, pg_loss=0.0222, v_loss=0.1699
Epoch: 322, global_step=32870400
Sampling new architecture
SPS: 2384, pg_loss=0.0244, v_loss=0.1730
Epoch: 323, global_step=32972800
Sampling new architecture
SPS: 2385, pg_loss=0.0345, v_loss=0.1709
Epoch: 324, global_step=33075200
Sampling new architecture
SPS: 2391, pg_loss=0.0181, v_loss=0.2678
Epoch: 325, global_step=33177600
Sampling new architecture
SPS: 2391, pg_loss=0.0335, v_loss=0.1946
Epoch: 326, global_step=33280000
Sampling new architecture
SPS: 2392, pg_loss=0.0436, v_loss=0.1727
Epoch: 327, global_step=33382400
Sampling new architecture
SPS: 2393, pg_loss=0.0354, v_loss=0.1933
Epoch: 328, global_step=33484800
Sampling new architecture
SPS: 2394, pg_loss=0.0291, v_loss=0.1900
Epoch: 329, global_step=33587200
Sampling new architecture
SPS: 2395, pg_loss=0.0387, v_loss=0.1616
Epoch: 330, global_step=33689600
Sampling new architecture
SPS: 2395, pg_loss=0.0382, v_loss=0.1977
Epoch: 331, global_step=33792000
Sampling new architecture
SPS: 2396, pg_loss=0.0501, v_loss=0.1963
Epoch: 332, global_step=33894400
Sampling new architecture
SPS: 2401, pg_loss=0.0630, v_loss=0.4812
Epoch: 333, global_step=33996800
Sampling new architecture
SPS: 2401, pg_loss=0.0216, v_loss=0.2423
Epoch: 334, global_step=34099200
Sampling new architecture
SPS: 2402, pg_loss=0.0426, v_loss=0.1730
Epoch: 335, global_step=34201600
Sampling new architecture
SPS: 2403, pg_loss=0.0291, v_loss=0.1537
Epoch: 336, global_step=34304000
Sampling new architecture
SPS: 2403, pg_loss=0.0223, v_loss=0.1697
Epoch: 337, global_step=34406400
Sampling new architecture
SPS: 2404, pg_loss=0.0220, v_loss=0.1369
Epoch: 338, global_step=34508800
Sampling new architecture
SPS: 2404, pg_loss=0.0454, v_loss=0.1574
Epoch: 339, global_step=34611200
Sampling new architecture
SPS: 2410, pg_loss=0.0567, v_loss=0.2206
Epoch: 340, global_step=34713600
Sampling new architecture
SPS: 2411, pg_loss=0.0440, v_loss=0.1823
Epoch: 341, global_step=34816000
Sampling new architecture
SPS: 2411, pg_loss=0.0448, v_loss=0.1849
Epoch: 342, global_step=34918400
Sampling new architecture
SPS: 2411, pg_loss=0.0418, v_loss=0.1898
Epoch: 343, global_step=35020800
Sampling new architecture
SPS: 2412, pg_loss=0.0380, v_loss=0.2001
Epoch: 344, global_step=35123200
Sampling new architecture
SPS: 2412, pg_loss=0.0474, v_loss=0.1937
Epoch: 345, global_step=35225600
Sampling new architecture
SPS: 2413, pg_loss=0.0586, v_loss=0.1894
Epoch: 346, global_step=35328000
Sampling new architecture
SPS: 2414, pg_loss=0.0343, v_loss=0.2144
Epoch: 347, global_step=35430400
Sampling new architecture
SPS: 2414, pg_loss=0.0304, v_loss=0.2152
Epoch: 348, global_step=35532800
Sampling new architecture
SPS: 2415, pg_loss=0.0389, v_loss=0.1895
Epoch: 349, global_step=35635200
Sampling new architecture
SPS: 2415, pg_loss=0.0338, v_loss=0.1518
Epoch: 350, global_step=35737600
Sampling new architecture
SPS: 2416, pg_loss=0.0410, v_loss=0.1860
Epoch: 351, global_step=35840000
Sampling new architecture
Evaluating
Initializing ContextualPandaStick...
Initializing ContextualPandaStick...
Evaluated 400 steps resulting in 8 episodes
Total reward during evaluation: 31.944768726825714
eval_success_once_mean=0.0
eval_return_mean=3.993095874786377
eval_episode_len_mean=50.0
eval_reward_mean=0.07986192405223846
eval_success_at_end_mean=0.0
model saved to runs/ContextualPushT-v1__Contextual_hyperppo__1__1747283748/ckpt_351.pt
SPS: 2415, pg_loss=0.0350, v_loss=0.1704
Epoch: 352, global_step=35942400
Sampling new architecture
SPS: 2416, pg_loss=0.0451, v_loss=0.1657
Epoch: 353, global_step=36044800
Sampling new architecture
SPS: 2417, pg_loss=0.0171, v_loss=0.1548
Epoch: 354, global_step=36147200
Sampling new architecture
SPS: 2418, pg_loss=0.0250, v_loss=0.1595
Epoch: 355, global_step=36249600
Sampling new architecture
SPS: 2419, pg_loss=0.0365, v_loss=0.1648
Epoch: 356, global_step=36352000
Sampling new architecture
SPS: 2420, pg_loss=0.0355, v_loss=0.1573
Epoch: 357, global_step=36454400
Sampling new architecture
SPS: 2421, pg_loss=0.0409, v_loss=0.1713
Epoch: 358, global_step=36556800
Sampling new architecture
SPS: 2422, pg_loss=0.0434, v_loss=0.1669
Epoch: 359, global_step=36659200
Sampling new architecture
SPS: 2423, pg_loss=0.0431, v_loss=0.2117
Epoch: 360, global_step=36761600
Sampling new architecture
SPS: 2424, pg_loss=0.0464, v_loss=0.1729
Epoch: 361, global_step=36864000
Sampling new architecture
SPS: 2425, pg_loss=0.0455, v_loss=0.1997
Epoch: 362, global_step=36966400
Sampling new architecture
SPS: 2425, pg_loss=0.0400, v_loss=0.1678
Epoch: 363, global_step=37068800
Sampling new architecture
SPS: 2426, pg_loss=0.0478, v_loss=0.1759
Epoch: 364, global_step=37171200
Sampling new architecture
SPS: 2427, pg_loss=0.0275, v_loss=0.1372
Epoch: 365, global_step=37273600
Sampling new architecture
SPS: 2427, pg_loss=0.0377, v_loss=0.1704
Epoch: 366, global_step=37376000
Sampling new architecture
SPS: 2427, pg_loss=0.0181, v_loss=0.1791
Epoch: 367, global_step=37478400
Sampling new architecture
SPS: 2428, pg_loss=0.0442, v_loss=0.1470
Epoch: 368, global_step=37580800
Sampling new architecture
SPS: 2429, pg_loss=0.0295, v_loss=0.1604
Epoch: 369, global_step=37683200
Sampling new architecture
SPS: 2433, pg_loss=0.0570, v_loss=0.3828
Epoch: 370, global_step=37785600
Sampling new architecture
SPS: 2434, pg_loss=0.0398, v_loss=0.1992
Epoch: 371, global_step=37888000
Sampling new architecture
SPS: 2435, pg_loss=0.0350, v_loss=0.1785
Epoch: 372, global_step=37990400
Sampling new architecture
SPS: 2436, pg_loss=0.0441, v_loss=0.1851
Epoch: 373, global_step=38092800
Sampling new architecture
SPS: 2436, pg_loss=0.0210, v_loss=0.1667
Epoch: 374, global_step=38195200
Sampling new architecture
SPS: 2441, pg_loss=0.0434, v_loss=0.2119
Epoch: 375, global_step=38297600
Sampling new architecture
SPS: 2442, pg_loss=0.0439, v_loss=0.1706
Epoch: 376, global_step=38400000
Sampling new architecture
SPS: 2446, pg_loss=0.0396, v_loss=0.2093
Epoch: 377, global_step=38502400
Sampling new architecture
SPS: 2450, pg_loss=0.0782, v_loss=0.5176
Epoch: 378, global_step=38604800
Sampling new architecture
SPS: 2454, pg_loss=0.0425, v_loss=0.2185
Epoch: 379, global_step=38707200
Sampling new architecture
SPS: 2459, pg_loss=0.0502, v_loss=0.2751
Epoch: 380, global_step=38809600
Sampling new architecture
SPS: 2463, pg_loss=0.0341, v_loss=0.2224
Epoch: 381, global_step=38912000
Sampling new architecture
SPS: 2464, pg_loss=0.0376, v_loss=0.1585
Epoch: 382, global_step=39014400
Sampling new architecture
SPS: 2464, pg_loss=0.0469, v_loss=0.1706
Epoch: 383, global_step=39116800
Sampling new architecture
SPS: 2469, pg_loss=0.0408, v_loss=0.1970
Epoch: 384, global_step=39219200
Sampling new architecture
SPS: 2469, pg_loss=0.0413, v_loss=0.1692
Epoch: 385, global_step=39321600
Sampling new architecture
SPS: 2471, pg_loss=0.0523, v_loss=0.1994
Epoch: 386, global_step=39424000
Sampling new architecture
SPS: 2476, pg_loss=0.0453, v_loss=0.2310
Epoch: 387, global_step=39526400
Sampling new architecture
SPS: 2476, pg_loss=0.0507, v_loss=0.1691
Epoch: 388, global_step=39628800
Sampling new architecture
SPS: 2477, pg_loss=0.0489, v_loss=0.1885
Epoch: 389, global_step=39731200
Sampling new architecture
SPS: 2478, pg_loss=0.0420, v_loss=0.1582
Epoch: 390, global_step=39833600
Sampling new architecture
SPS: 2479, pg_loss=0.0372, v_loss=0.1668
Epoch: 391, global_step=39936000
Sampling new architecture
SPS: 2482, pg_loss=0.0318, v_loss=0.1774
Epoch: 392, global_step=40038400
Sampling new architecture
SPS: 2483, pg_loss=0.0503, v_loss=0.1704
Epoch: 393, global_step=40140800
Sampling new architecture
SPS: 2487, pg_loss=0.0330, v_loss=0.2363
Epoch: 394, global_step=40243200
Sampling new architecture
SPS: 2488, pg_loss=0.0392, v_loss=0.1788
Epoch: 395, global_step=40345600
Sampling new architecture
SPS: 2488, pg_loss=0.0652, v_loss=0.1635
Epoch: 396, global_step=40448000
Sampling new architecture
SPS: 2490, pg_loss=0.0330, v_loss=0.1774
Epoch: 397, global_step=40550400
Sampling new architecture
SPS: 2491, pg_loss=0.0304, v_loss=0.1736
Epoch: 398, global_step=40652800
Sampling new architecture
SPS: 2491, pg_loss=0.0223, v_loss=0.1519
Epoch: 399, global_step=40755200
Sampling new architecture
SPS: 2491, pg_loss=0.0390, v_loss=0.1651
Epoch: 400, global_step=40857600
Sampling new architecture
SPS: 2496, pg_loss=0.0496, v_loss=0.2571
Epoch: 401, global_step=40960000
Sampling new architecture
Evaluating
Initializing ContextualPandaStick...
Initializing ContextualPandaStick...
Evaluated 400 steps resulting in 8 episodes
Total reward during evaluation: 47.4403817653656
eval_success_once_mean=0.0
eval_return_mean=5.930047512054443
eval_episode_len_mean=50.0
eval_reward_mean=0.11860095709562302
eval_success_at_end_mean=0.0
model saved to runs/ContextualPushT-v1__Contextual_hyperppo__1__1747283748/ckpt_401.pt
SPS: 2495, pg_loss=0.0451, v_loss=0.1745
Epoch: 402, global_step=41062400
Sampling new architecture
SPS: 2496, pg_loss=0.0415, v_loss=0.1570
Epoch: 403, global_step=41164800
Sampling new architecture
SPS: 2496, pg_loss=0.0505, v_loss=0.1875
Epoch: 404, global_step=41267200
Sampling new architecture
SPS: 2501, pg_loss=0.0547, v_loss=0.2850
Epoch: 405, global_step=41369600
Sampling new architecture
SPS: 2505, pg_loss=0.0490, v_loss=0.2337
Epoch: 406, global_step=41472000
Sampling new architecture
SPS: 2506, pg_loss=0.0496, v_loss=0.2092
Epoch: 407, global_step=41574400
Sampling new architecture
SPS: 2506, pg_loss=0.0151, v_loss=0.1666
Epoch: 408, global_step=41676800
Sampling new architecture
SPS: 2506, pg_loss=0.0234, v_loss=0.1432
Epoch: 409, global_step=41779200
Sampling new architecture
SPS: 2507, pg_loss=0.0600, v_loss=0.1643
Epoch: 410, global_step=41881600
Sampling new architecture
SPS: 2508, pg_loss=0.0529, v_loss=0.1728
Epoch: 411, global_step=41984000
Sampling new architecture
SPS: 2513, pg_loss=0.0339, v_loss=0.2189
Epoch: 412, global_step=42086400
Sampling new architecture
SPS: 2517, pg_loss=0.0451, v_loss=0.2355
Epoch: 413, global_step=42188800
Sampling new architecture
SPS: 2520, pg_loss=0.0385, v_loss=0.2133
Epoch: 414, global_step=42291200
Sampling new architecture
SPS: 2524, pg_loss=0.0605, v_loss=0.2247
Epoch: 415, global_step=42393600
Sampling new architecture
SPS: 2529, pg_loss=0.0576, v_loss=0.2508
Epoch: 416, global_step=42496000
Sampling new architecture
SPS: 2529, pg_loss=0.0226, v_loss=0.1900
Epoch: 417, global_step=42598400
Sampling new architecture
SPS: 2533, pg_loss=0.0474, v_loss=0.2204
Epoch: 418, global_step=42700800
Sampling new architecture
SPS: 2537, pg_loss=0.0386, v_loss=0.2511
Epoch: 419, global_step=42803200
Sampling new architecture
SPS: 2541, pg_loss=0.0526, v_loss=0.2410
Epoch: 420, global_step=42905600
Sampling new architecture
SPS: 2545, pg_loss=0.0458, v_loss=0.3013
Epoch: 421, global_step=43008000
Sampling new architecture
SPS: 2545, pg_loss=0.0443, v_loss=0.2189
Epoch: 422, global_step=43110400
Sampling new architecture
SPS: 2546, pg_loss=0.0399, v_loss=0.1875
Epoch: 423, global_step=43212800
Sampling new architecture
SPS: 2548, pg_loss=0.0579, v_loss=0.2118
Epoch: 424, global_step=43315200
Sampling new architecture
SPS: 2549, pg_loss=0.0553, v_loss=0.2008
Epoch: 425, global_step=43417600
Sampling new architecture
SPS: 2550, pg_loss=0.0508, v_loss=0.1692
Epoch: 426, global_step=43520000
Sampling new architecture
SPS: 2550, pg_loss=0.0498, v_loss=0.2155
Epoch: 427, global_step=43622400
Sampling new architecture
SPS: 2554, pg_loss=0.0424, v_loss=0.2092
Epoch: 428, global_step=43724800
Sampling new architecture
SPS: 2554, pg_loss=0.0283, v_loss=0.1660
Epoch: 429, global_step=43827200
Sampling new architecture
SPS: 2559, pg_loss=0.0687, v_loss=0.2435
Epoch: 430, global_step=43929600
Sampling new architecture
SPS: 2563, pg_loss=0.0608, v_loss=0.2271
Epoch: 431, global_step=44032000
Sampling new architecture
SPS: 2563, pg_loss=0.0361, v_loss=0.1805
Epoch: 432, global_step=44134400
Sampling new architecture
SPS: 2566, pg_loss=0.0243, v_loss=0.2055
Epoch: 433, global_step=44236800
Sampling new architecture
SPS: 2571, pg_loss=0.0360, v_loss=0.2227
Epoch: 434, global_step=44339200
Sampling new architecture
SPS: 2575, pg_loss=0.0663, v_loss=0.2262
Epoch: 435, global_step=44441600
Sampling new architecture
SPS: 2575, pg_loss=0.0214, v_loss=0.1978
Epoch: 436, global_step=44544000
Sampling new architecture
SPS: 2580, pg_loss=0.0656, v_loss=0.1924
Epoch: 437, global_step=44646400
Sampling new architecture
SPS: 2581, pg_loss=0.0515, v_loss=0.1889
Epoch: 438, global_step=44748800
Sampling new architecture
SPS: 2585, pg_loss=0.0574, v_loss=0.2665
Epoch: 439, global_step=44851200
Sampling new architecture
SPS: 2586, pg_loss=0.0575, v_loss=0.2099
Epoch: 440, global_step=44953600
Sampling new architecture
SPS: 2590, pg_loss=0.0404, v_loss=0.2623
Epoch: 441, global_step=45056000
Sampling new architecture
SPS: 2591, pg_loss=0.0423, v_loss=0.2299
Epoch: 442, global_step=45158400
Sampling new architecture
SPS: 2595, pg_loss=0.0846, v_loss=0.3105
Epoch: 443, global_step=45260800
Sampling new architecture
SPS: 2599, pg_loss=0.0396, v_loss=0.2535
Epoch: 444, global_step=45363200
Sampling new architecture
SPS: 2603, pg_loss=0.0291, v_loss=0.2548
Epoch: 445, global_step=45465600
Sampling new architecture
SPS: 2608, pg_loss=0.0416, v_loss=0.2627
Epoch: 446, global_step=45568000
Sampling new architecture
SPS: 2608, pg_loss=0.0383, v_loss=0.2069
Epoch: 447, global_step=45670400
Sampling new architecture
SPS: 2609, pg_loss=0.0397, v_loss=0.2190
Epoch: 448, global_step=45772800
Sampling new architecture
SPS: 2609, pg_loss=0.0509, v_loss=0.1959
Epoch: 449, global_step=45875200
Sampling new architecture
SPS: 2609, pg_loss=0.0308, v_loss=0.2125
Epoch: 450, global_step=45977600
Sampling new architecture
SPS: 2613, pg_loss=0.0545, v_loss=0.2212
Epoch: 451, global_step=46080000
Sampling new architecture
Evaluating
Initializing ContextualPandaStick...
Initializing ContextualPandaStick...
Evaluated 400 steps resulting in 8 episodes
Total reward during evaluation: 38.76603180170059
eval_success_once_mean=0.0
eval_return_mean=4.845754146575928
eval_episode_len_mean=50.0
eval_reward_mean=0.09691508114337921
eval_success_at_end_mean=0.0
model saved to runs/ContextualPushT-v1__Contextual_hyperppo__1__1747283748/ckpt_451.pt
SPS: 2614, pg_loss=0.0464, v_loss=0.1997
Epoch: 452, global_step=46182400
Sampling new architecture
SPS: 2618, pg_loss=0.0512, v_loss=0.2470
Epoch: 453, global_step=46284800
Sampling new architecture
SPS: 2618, pg_loss=0.0500, v_loss=0.2366
Epoch: 454, global_step=46387200
Sampling new architecture
SPS: 2622, pg_loss=0.0469, v_loss=0.2849
Epoch: 455, global_step=46489600
Sampling new architecture
SPS: 2626, pg_loss=0.0400, v_loss=0.2518
Epoch: 456, global_step=46592000
Sampling new architecture
SPS: 2627, pg_loss=0.0368, v_loss=0.2322
Epoch: 457, global_step=46694400
Sampling new architecture
SPS: 2631, pg_loss=0.0401, v_loss=0.2697
Epoch: 458, global_step=46796800
Sampling new architecture
SPS: 2636, pg_loss=0.0517, v_loss=0.3072
Epoch: 459, global_step=46899200
Sampling new architecture
SPS: 2637, pg_loss=0.0330, v_loss=0.3172
Epoch: 460, global_step=47001600
Sampling new architecture
SPS: 2641, pg_loss=0.0432, v_loss=0.3543
Epoch: 461, global_step=47104000
Sampling new architecture
SPS: 2642, pg_loss=0.0623, v_loss=0.2507
Epoch: 462, global_step=47206400
Sampling new architecture
SPS: 2642, pg_loss=0.0550, v_loss=0.1885
Epoch: 463, global_step=47308800
Sampling new architecture
SPS: 2642, pg_loss=0.0591, v_loss=0.2462
Epoch: 464, global_step=47411200
Sampling new architecture
SPS: 2646, pg_loss=0.0415, v_loss=0.2927
Epoch: 465, global_step=47513600
Sampling new architecture
SPS: 2649, pg_loss=0.0684, v_loss=0.2908
Epoch: 466, global_step=47616000
Sampling new architecture
SPS: 2654, pg_loss=0.0406, v_loss=0.2905
Epoch: 467, global_step=47718400
Sampling new architecture
SPS: 2658, pg_loss=0.0421, v_loss=0.2661
Epoch: 468, global_step=47820800
Sampling new architecture
SPS: 2661, pg_loss=0.0488, v_loss=0.3151
Epoch: 469, global_step=47923200
Sampling new architecture
SPS: 2662, pg_loss=0.0474, v_loss=0.2573
Epoch: 470, global_step=48025600
Sampling new architecture
SPS: 2666, pg_loss=0.0438, v_loss=0.3086
Epoch: 471, global_step=48128000
Sampling new architecture
SPS: 2670, pg_loss=0.0555, v_loss=0.3393
Epoch: 472, global_step=48230400
Sampling new architecture
SPS: 2674, pg_loss=0.0369, v_loss=0.3270
Epoch: 473, global_step=48332800
Sampling new architecture
SPS: 2678, pg_loss=0.0762, v_loss=0.3115
Epoch: 474, global_step=48435200
Sampling new architecture
SPS: 2682, pg_loss=0.0435, v_loss=0.3563
Epoch: 475, global_step=48537600
Sampling new architecture
SPS: 2685, pg_loss=0.0510, v_loss=0.2980
Epoch: 476, global_step=48640000
Sampling new architecture
SPS: 2689, pg_loss=0.0517, v_loss=0.3297
Epoch: 477, global_step=48742400
Sampling new architecture
SPS: 2693, pg_loss=0.0657, v_loss=0.3567
Epoch: 478, global_step=48844800
Sampling new architecture
SPS: 2697, pg_loss=0.0219, v_loss=0.3619
Epoch: 479, global_step=48947200
Sampling new architecture
SPS: 2701, pg_loss=0.0519, v_loss=0.3161
Epoch: 480, global_step=49049600
Sampling new architecture
SPS: 2704, pg_loss=0.0288, v_loss=0.2721
Epoch: 481, global_step=49152000
Sampling new architecture
SPS: 2708, pg_loss=0.0369, v_loss=0.3285
Epoch: 482, global_step=49254400
Sampling new architecture
SPS: 2712, pg_loss=0.0572, v_loss=0.3677
Epoch: 483, global_step=49356800
Sampling new architecture
SPS: 2715, pg_loss=0.0223, v_loss=0.3335
Epoch: 484, global_step=49459200
Sampling new architecture
SPS: 2719, pg_loss=0.0296, v_loss=0.3695
Epoch: 485, global_step=49561600
Sampling new architecture
SPS: 2723, pg_loss=0.0230, v_loss=0.3279
Epoch: 486, global_step=49664000
Sampling new architecture
SPS: 2727, pg_loss=0.0711, v_loss=0.3360
Epoch: 487, global_step=49766400
Sampling new architecture
SPS: 2731, pg_loss=0.0650, v_loss=0.3221
Epoch: 488, global_step=49868800
Sampling new architecture
SPS: 2735, pg_loss=0.0628, v_loss=0.3707
Epoch: 489, global_step=49971200
Sampling new architecture
SPS: 2739, pg_loss=0.0491, v_loss=0.3602
Epoch: 490, global_step=50073600
Sampling new architecture
SPS: 2742, pg_loss=0.0374, v_loss=0.2916
Epoch: 491, global_step=50176000
Sampling new architecture
SPS: 2746, pg_loss=0.0591, v_loss=0.3266
Epoch: 492, global_step=50278400
Sampling new architecture
SPS: 2750, pg_loss=0.0323, v_loss=0.3100
Epoch: 493, global_step=50380800
Sampling new architecture
SPS: 2754, pg_loss=0.0703, v_loss=0.3235
Epoch: 494, global_step=50483200
Sampling new architecture
SPS: 2758, pg_loss=0.0756, v_loss=0.3403
Epoch: 495, global_step=50585600
Sampling new architecture
SPS: 2762, pg_loss=0.0279, v_loss=0.3527
Epoch: 496, global_step=50688000
Sampling new architecture
SPS: 2765, pg_loss=0.0456, v_loss=0.2853
Epoch: 497, global_step=50790400
Sampling new architecture
SPS: 2769, pg_loss=0.0486, v_loss=0.3094
Epoch: 498, global_step=50892800
Sampling new architecture
SPS: 2773, pg_loss=0.0621, v_loss=0.3413
Epoch: 499, global_step=50995200
Sampling new architecture
SPS: 2777, pg_loss=0.0345, v_loss=0.2986
Epoch: 500, global_step=51097600
Sampling new architecture
SPS: 2781, pg_loss=0.0654, v_loss=0.3673
Epoch: 501, global_step=51200000
Sampling new architecture
Evaluating
Initializing ContextualPandaStick...
Initializing ContextualPandaStick...
Evaluated 400 steps resulting in 8 episodes
Total reward during evaluation: 56.33613693714142
eval_success_once_mean=0.0
eval_return_mean=7.042016983032227
eval_episode_len_mean=50.0
eval_reward_mean=0.1408403515815735
eval_success_at_end_mean=0.0
model saved to runs/ContextualPushT-v1__Contextual_hyperppo__1__1747283748/ckpt_501.pt
SPS: 2779, pg_loss=0.0194, v_loss=0.2104
Epoch: 502, global_step=51302400
Sampling new architecture
SPS: 2783, pg_loss=0.0480, v_loss=0.2623
Epoch: 503, global_step=51404800
Sampling new architecture
SPS: 2787, pg_loss=0.0610, v_loss=0.2992
Epoch: 504, global_step=51507200
Sampling new architecture
SPS: 2790, pg_loss=0.0529, v_loss=0.3093
Epoch: 505, global_step=51609600
Sampling new architecture
SPS: 2794, pg_loss=0.0619, v_loss=0.3339
Epoch: 506, global_step=51712000
Sampling new architecture
SPS: 2798, pg_loss=0.0451, v_loss=0.3375
Epoch: 507, global_step=51814400
Sampling new architecture
SPS: 2802, pg_loss=0.0588, v_loss=0.3504
Epoch: 508, global_step=51916800
Sampling new architecture
SPS: 2805, pg_loss=0.0307, v_loss=0.3611
Epoch: 509, global_step=52019200
Sampling new architecture
SPS: 2807, pg_loss=0.0357, v_loss=0.2511
Epoch: 510, global_step=52121600
Sampling new architecture
SPS: 2811, pg_loss=0.0855, v_loss=0.2998
Epoch: 511, global_step=52224000
Sampling new architecture
SPS: 2815, pg_loss=0.1060, v_loss=0.3581
Epoch: 512, global_step=52326400
Sampling new architecture
SPS: 2819, pg_loss=0.1467, v_loss=0.2822
Epoch: 513, global_step=52428800
Sampling new architecture
SPS: 2822, pg_loss=0.0448, v_loss=0.3133
Epoch: 514, global_step=52531200
Sampling new architecture
SPS: 2826, pg_loss=0.0520, v_loss=0.3612
Epoch: 515, global_step=52633600
Sampling new architecture
SPS: 2830, pg_loss=0.0494, v_loss=0.3157
Epoch: 516, global_step=52736000
Sampling new architecture
SPS: 2834, pg_loss=0.0419, v_loss=0.3619
Epoch: 517, global_step=52838400
Sampling new architecture
SPS: 2833, pg_loss=0.0254, v_loss=0.2236
Epoch: 518, global_step=52940800
Sampling new architecture
SPS: 2836, pg_loss=0.0337, v_loss=0.2666
Epoch: 519, global_step=53043200
Sampling new architecture
SPS: 2840, pg_loss=0.0563, v_loss=0.2997
Epoch: 520, global_step=53145600
Sampling new architecture
SPS: 2844, pg_loss=0.0323, v_loss=0.3031
Epoch: 521, global_step=53248000
Sampling new architecture
SPS: 2847, pg_loss=0.0822, v_loss=0.3539
Epoch: 522, global_step=53350400
Sampling new architecture
SPS: 2851, pg_loss=0.0554, v_loss=0.3728
Epoch: 523, global_step=53452800
Sampling new architecture
SPS: 2853, pg_loss=0.0302, v_loss=0.3094
Epoch: 524, global_step=53555200
Sampling new architecture
SPS: 2856, pg_loss=0.0367, v_loss=0.2760
Epoch: 525, global_step=53657600
Sampling new architecture
SPS: 2860, pg_loss=0.0512, v_loss=0.3051
Epoch: 526, global_step=53760000
Sampling new architecture
SPS: 2864, pg_loss=0.0602, v_loss=0.3545
Epoch: 527, global_step=53862400
Sampling new architecture
SPS: 2867, pg_loss=0.0576, v_loss=0.3751
Epoch: 528, global_step=53964800
Sampling new architecture
SPS: 2871, pg_loss=0.0600, v_loss=0.3910
Epoch: 529, global_step=54067200
Sampling new architecture
SPS: 2875, pg_loss=0.0597, v_loss=0.4260
Epoch: 530, global_step=54169600
Sampling new architecture
SPS: 2878, pg_loss=0.0636, v_loss=0.3787
Epoch: 531, global_step=54272000
Sampling new architecture
SPS: 2882, pg_loss=0.0545, v_loss=0.3939
Epoch: 532, global_step=54374400
Sampling new architecture
SPS: 2886, pg_loss=0.0504, v_loss=0.3844
Epoch: 533, global_step=54476800
Sampling new architecture
SPS: 2889, pg_loss=0.0594, v_loss=0.3549
Epoch: 534, global_step=54579200
Sampling new architecture
SPS: 2893, pg_loss=0.0323, v_loss=0.3411
Epoch: 535, global_step=54681600
Sampling new architecture
SPS: 2896, pg_loss=0.0816, v_loss=0.3704
Epoch: 536, global_step=54784000
Sampling new architecture
SPS: 2900, pg_loss=0.0588, v_loss=0.4477
Epoch: 537, global_step=54886400
Sampling new architecture
SPS: 2904, pg_loss=0.0668, v_loss=0.4911
Epoch: 538, global_step=54988800
Sampling new architecture
SPS: 2907, pg_loss=0.0521, v_loss=0.4367
Epoch: 539, global_step=55091200
Sampling new architecture
SPS: 2911, pg_loss=0.0599, v_loss=0.4068
Epoch: 540, global_step=55193600
Sampling new architecture
SPS: 2914, pg_loss=0.0208, v_loss=0.4191
Epoch: 541, global_step=55296000
Sampling new architecture
SPS: 2918, pg_loss=0.0643, v_loss=0.3851
Epoch: 542, global_step=55398400
Sampling new architecture
SPS: 2921, pg_loss=0.0540, v_loss=0.3868
Epoch: 543, global_step=55500800
Sampling new architecture
SPS: 2925, pg_loss=0.0701, v_loss=0.3723
Epoch: 544, global_step=55603200
Sampling new architecture
SPS: 2928, pg_loss=0.0700, v_loss=0.3530
Epoch: 545, global_step=55705600
Sampling new architecture
SPS: 2932, pg_loss=0.0576, v_loss=0.4089
Epoch: 546, global_step=55808000
Sampling new architecture
SPS: 2936, pg_loss=0.0298, v_loss=0.3563
Epoch: 547, global_step=55910400
Sampling new architecture
SPS: 2935, pg_loss=0.0366, v_loss=0.2740
Epoch: 548, global_step=56012800
Sampling new architecture
SPS: 2938, pg_loss=0.0548, v_loss=0.3061
Epoch: 549, global_step=56115200
Sampling new architecture
SPS: 2942, pg_loss=0.0464, v_loss=0.3742
Epoch: 550, global_step=56217600
Sampling new architecture
SPS: 2945, pg_loss=0.0591, v_loss=0.3358
Epoch: 551, global_step=56320000
Sampling new architecture
Evaluating
Initializing ContextualPandaStick...
Initializing ContextualPandaStick...
Evaluated 400 steps resulting in 8 episodes
Total reward during evaluation: 54.198902010917664
eval_success_once_mean=0.0
eval_return_mean=6.774863243103027
eval_episode_len_mean=50.0
eval_reward_mean=0.13549725711345673
eval_success_at_end_mean=0.0
model saved to runs/ContextualPushT-v1__Contextual_hyperppo__1__1747283748/ckpt_551.pt
SPS: 2948, pg_loss=0.1223, v_loss=0.3965
Epoch: 552, global_step=56422400
Sampling new architecture
SPS: 2951, pg_loss=0.0772, v_loss=0.3387
Epoch: 553, global_step=56524800
Sampling new architecture
SPS: 2955, pg_loss=0.0447, v_loss=0.3590
Epoch: 554, global_step=56627200
Sampling new architecture
SPS: 2958, pg_loss=0.0794, v_loss=0.3721
Epoch: 555, global_step=56729600
Sampling new architecture
SPS: 2962, pg_loss=0.0497, v_loss=0.3509
Epoch: 556, global_step=56832000
Sampling new architecture
SPS: 2965, pg_loss=0.1206, v_loss=0.3821
Epoch: 557, global_step=56934400
Sampling new architecture
SPS: 2969, pg_loss=0.0855, v_loss=0.2994
Epoch: 558, global_step=57036800
Sampling new architecture
SPS: 2968, pg_loss=0.0317, v_loss=0.2432
Epoch: 559, global_step=57139200
Sampling new architecture
SPS: 2971, pg_loss=0.0745, v_loss=0.3060
Epoch: 560, global_step=57241600
Sampling new architecture
SPS: 2975, pg_loss=0.0396, v_loss=0.3135
Epoch: 561, global_step=57344000
Sampling new architecture
SPS: 2978, pg_loss=0.0449, v_loss=0.3741
Epoch: 562, global_step=57446400
Sampling new architecture
SPS: 2982, pg_loss=0.0490, v_loss=0.3657
Epoch: 563, global_step=57548800
Sampling new architecture
SPS: 2985, pg_loss=0.0937, v_loss=0.3706
Epoch: 564, global_step=57651200
Sampling new architecture
SPS: 2989, pg_loss=0.0286, v_loss=0.3880
Epoch: 565, global_step=57753600
Sampling new architecture
SPS: 2991, pg_loss=0.0407, v_loss=0.3032
Epoch: 566, global_step=57856000
Sampling new architecture
SPS: 2994, pg_loss=0.0221, v_loss=0.3720
Epoch: 567, global_step=57958400
Sampling new architecture
SPS: 2997, pg_loss=0.0320, v_loss=0.3612
Epoch: 568, global_step=58060800
Sampling new architecture
SPS: 3001, pg_loss=0.0654, v_loss=0.3538
Epoch: 569, global_step=58163200
Sampling new architecture
SPS: 3004, pg_loss=0.0535, v_loss=0.3925
Epoch: 570, global_step=58265600
Sampling new architecture
SPS: 3007, pg_loss=0.0509, v_loss=0.3868
Epoch: 571, global_step=58368000
Sampling new architecture
SPS: 3006, pg_loss=0.0261, v_loss=0.2880
Epoch: 572, global_step=58470400
Sampling new architecture
SPS: 3010, pg_loss=0.0673, v_loss=0.3180
Epoch: 573, global_step=58572800
Sampling new architecture
SPS: 3013, pg_loss=0.0600, v_loss=0.3293
Epoch: 574, global_step=58675200
Sampling new architecture
SPS: 3017, pg_loss=0.0390, v_loss=0.3395
Epoch: 575, global_step=58777600
Sampling new architecture
SPS: 3019, pg_loss=0.0401, v_loss=0.3104
Epoch: 576, global_step=58880000
Sampling new architecture
SPS: 3023, pg_loss=0.1038, v_loss=0.3451
Epoch: 577, global_step=58982400
Sampling new architecture
SPS: 3026, pg_loss=0.0620, v_loss=0.3546
Epoch: 578, global_step=59084800
Sampling new architecture
SPS: 3030, pg_loss=0.0641, v_loss=0.3166
Epoch: 579, global_step=59187200
Sampling new architecture
SPS: 3033, pg_loss=0.0843, v_loss=0.3840
Epoch: 580, global_step=59289600
Sampling new architecture
SPS: 3037, pg_loss=0.0702, v_loss=0.3868
Epoch: 581, global_step=59392000
Sampling new architecture
SPS: 3040, pg_loss=0.0528, v_loss=0.4139
Epoch: 582, global_step=59494400
Sampling new architecture
SPS: 3043, pg_loss=0.0423, v_loss=0.3991
Epoch: 583, global_step=59596800
Sampling new architecture
SPS: 3047, pg_loss=0.0462, v_loss=0.4077
Epoch: 584, global_step=59699200
Sampling new architecture
SPS: 3050, pg_loss=0.0497, v_loss=0.4517
Epoch: 585, global_step=59801600
Sampling new architecture
SPS: 3053, pg_loss=0.0629, v_loss=0.3919
Epoch: 586, global_step=59904000
Sampling new architecture
SPS: 3057, pg_loss=0.0278, v_loss=0.4061
Epoch: 587, global_step=60006400
Sampling new architecture
SPS: 3060, pg_loss=0.0205, v_loss=0.4040
Epoch: 588, global_step=60108800
Sampling new architecture
SPS: 3063, pg_loss=0.0992, v_loss=0.3789
Epoch: 589, global_step=60211200
Sampling new architecture
SPS: 3067, pg_loss=0.0457, v_loss=0.3867
Epoch: 590, global_step=60313600
Sampling new architecture
SPS: 3070, pg_loss=0.0629, v_loss=0.4234
Epoch: 591, global_step=60416000
Sampling new architecture
SPS: 3073, pg_loss=0.0339, v_loss=0.4040
Epoch: 592, global_step=60518400
Sampling new architecture
SPS: 3076, pg_loss=0.0942, v_loss=0.3979
Epoch: 593, global_step=60620800
Sampling new architecture
SPS: 3080, pg_loss=0.0682, v_loss=0.4377
Epoch: 594, global_step=60723200
Sampling new architecture
SPS: 3083, pg_loss=0.0474, v_loss=0.4807
Epoch: 595, global_step=60825600
Sampling new architecture
SPS: 3087, pg_loss=0.0476, v_loss=0.3910
Epoch: 596, global_step=60928000
Sampling new architecture
SPS: 3090, pg_loss=0.0807, v_loss=0.3902
Epoch: 597, global_step=61030400
Sampling new architecture
SPS: 3089, pg_loss=0.0202, v_loss=0.2961
Epoch: 598, global_step=61132800
Sampling new architecture
SPS: 3092, pg_loss=0.0692, v_loss=0.3532
Epoch: 599, global_step=61235200
Sampling new architecture
SPS: 3091, pg_loss=0.0240, v_loss=0.2516
Epoch: 600, global_step=61337600
Sampling new architecture
SPS: 3094, pg_loss=0.0595, v_loss=0.3171
Epoch: 601, global_step=61440000
Sampling new architecture
Evaluating
Initializing ContextualPandaStick...
Initializing ContextualPandaStick...
Evaluated 400 steps resulting in 8 episodes
Total reward during evaluation: 31.550580501556396
eval_success_once_mean=0.0
eval_return_mean=3.9438223838806152
eval_episode_len_mean=50.0
eval_reward_mean=0.07887645065784454
eval_success_at_end_mean=0.0
model saved to runs/ContextualPushT-v1__Contextual_hyperppo__1__1747283748/ckpt_601.pt
SPS: 3092, pg_loss=0.0176, v_loss=0.2923
Epoch: 602, global_step=61542400
Sampling new architecture
SPS: 3096, pg_loss=0.0639, v_loss=0.3657
Epoch: 603, global_step=61644800
Sampling new architecture
SPS: 3099, pg_loss=0.0518, v_loss=0.3153
Epoch: 604, global_step=61747200
Sampling new architecture
SPS: 3102, pg_loss=0.0392, v_loss=0.3629
Epoch: 605, global_step=61849600
Sampling new architecture
SPS: 3101, pg_loss=0.0516, v_loss=0.3089
Epoch: 606, global_step=61952000
Sampling new architecture
SPS: 3102, pg_loss=0.0476, v_loss=0.2848
Epoch: 607, global_step=62054400
Sampling new architecture
SPS: 3105, pg_loss=0.0608, v_loss=0.3605
Epoch: 608, global_step=62156800
Sampling new architecture
SPS: 3108, pg_loss=0.0505, v_loss=0.3475
Epoch: 609, global_step=62259200
Sampling new architecture
SPS: 3107, pg_loss=0.0572, v_loss=0.2668
Epoch: 610, global_step=62361600
Sampling new architecture
SPS: 3107, pg_loss=0.0505, v_loss=0.3140
Epoch: 611, global_step=62464000
Sampling new architecture
SPS: 3106, pg_loss=0.0361, v_loss=0.2921
Epoch: 612, global_step=62566400
Sampling new architecture
SPS: 3109, pg_loss=0.0447, v_loss=0.3265
Epoch: 613, global_step=62668800
Sampling new architecture
SPS: 3112, pg_loss=0.0424, v_loss=0.2717
Epoch: 614, global_step=62771200
Sampling new architecture
SPS: 3111, pg_loss=0.0261, v_loss=0.2812
Epoch: 615, global_step=62873600
Sampling new architecture
SPS: 3114, pg_loss=0.0736, v_loss=0.3251
Epoch: 616, global_step=62976000
Sampling new architecture
SPS: 3117, pg_loss=0.0257, v_loss=0.3623
Epoch: 617, global_step=63078400
Sampling new architecture
SPS: 3121, pg_loss=0.0623, v_loss=0.3227
Epoch: 618, global_step=63180800
Sampling new architecture
SPS: 3124, pg_loss=0.0709, v_loss=0.4025
Epoch: 619, global_step=63283200
Sampling new architecture
SPS: 3127, pg_loss=0.0659, v_loss=0.3531
Epoch: 620, global_step=63385600
Sampling new architecture
SPS: 3126, pg_loss=0.0372, v_loss=0.3335
Epoch: 621, global_step=63488000
Sampling new architecture
SPS: 3129, pg_loss=0.0516, v_loss=0.3128
Epoch: 622, global_step=63590400
Sampling new architecture
SPS: 3133, pg_loss=0.0703, v_loss=0.3227
Epoch: 623, global_step=63692800
Sampling new architecture
SPS: 3136, pg_loss=0.0587, v_loss=0.3462
Epoch: 624, global_step=63795200
Sampling new architecture
SPS: 3135, pg_loss=0.0294, v_loss=0.2400
Epoch: 625, global_step=63897600
Sampling new architecture
SPS: 3138, pg_loss=0.0660, v_loss=0.3052
Epoch: 626, global_step=64000000
Sampling new architecture
SPS: 3142, pg_loss=0.0550, v_loss=0.3252
Epoch: 627, global_step=64102400
Sampling new architecture
SPS: 3145, pg_loss=0.0546, v_loss=0.3156
Epoch: 628, global_step=64204800
Sampling new architecture
SPS: 3148, pg_loss=0.0299, v_loss=0.3702
Epoch: 629, global_step=64307200
Sampling new architecture
SPS: 3151, pg_loss=0.0538, v_loss=0.3528
Epoch: 630, global_step=64409600
Sampling new architecture
SPS: 3154, pg_loss=0.0467, v_loss=0.3859
Epoch: 631, global_step=64512000
Sampling new architecture
SPS: 3158, pg_loss=0.0320, v_loss=0.4023
Epoch: 632, global_step=64614400
Sampling new architecture
SPS: 3161, pg_loss=0.0502, v_loss=0.3737
Epoch: 633, global_step=64716800
Sampling new architecture
SPS: 3164, pg_loss=0.0252, v_loss=0.4260
Epoch: 634, global_step=64819200
Sampling new architecture
SPS: 3167, pg_loss=0.0709, v_loss=0.4882
Epoch: 635, global_step=64921600
Sampling new architecture
SPS: 3166, pg_loss=0.0265, v_loss=0.3345
Epoch: 636, global_step=65024000
Sampling new architecture
SPS: 3169, pg_loss=0.0597, v_loss=0.3455
Epoch: 637, global_step=65126400
Sampling new architecture
SPS: 3172, pg_loss=0.0620, v_loss=0.3222
Epoch: 638, global_step=65228800
Sampling new architecture
SPS: 3175, pg_loss=0.0405, v_loss=0.3708
Epoch: 639, global_step=65331200
Sampling new architecture
SPS: 3178, pg_loss=0.0416, v_loss=0.3708
Epoch: 640, global_step=65433600
Sampling new architecture
SPS: 3182, pg_loss=0.0413, v_loss=0.4067
Epoch: 641, global_step=65536000
Sampling new architecture
SPS: 3185, pg_loss=0.0386, v_loss=0.3804
Epoch: 642, global_step=65638400
Sampling new architecture
SPS: 3188, pg_loss=0.2169, v_loss=0.3860
Epoch: 643, global_step=65740800
Sampling new architecture
SPS: 3191, pg_loss=0.0686, v_loss=0.3934
Epoch: 644, global_step=65843200
Sampling new architecture
SPS: 3194, pg_loss=0.0850, v_loss=0.3840
Epoch: 645, global_step=65945600
Sampling new architecture
SPS: 3197, pg_loss=0.0702, v_loss=0.3842
Epoch: 646, global_step=66048000
Sampling new architecture
SPS: 3200, pg_loss=0.0303, v_loss=0.3842
Epoch: 647, global_step=66150400
Sampling new architecture
SPS: 3203, pg_loss=0.0305, v_loss=0.3859
Epoch: 648, global_step=66252800
Sampling new architecture
SPS: 3207, pg_loss=0.0634, v_loss=0.4011
Epoch: 649, global_step=66355200
Sampling new architecture
SPS: 3210, pg_loss=0.0494, v_loss=0.3569
Epoch: 650, global_step=66457600
Sampling new architecture
SPS: 3213, pg_loss=0.0419, v_loss=0.4384
Epoch: 651, global_step=66560000
Sampling new architecture
Evaluating
Initializing ContextualPandaStick...
Initializing ContextualPandaStick...
Evaluated 400 steps resulting in 8 episodes
Total reward during evaluation: 64.64358520507812
eval_success_once_mean=0.0
eval_return_mean=8.080448150634766
eval_episode_len_mean=50.0
eval_reward_mean=0.1616089642047882
eval_success_at_end_mean=0.0
model saved to runs/ContextualPushT-v1__Contextual_hyperppo__1__1747283748/ckpt_651.pt
SPS: 3215, pg_loss=0.0514, v_loss=0.3951
Epoch: 652, global_step=66662400
Sampling new architecture
SPS: 3218, pg_loss=0.0565, v_loss=0.3801
Epoch: 653, global_step=66764800
Sampling new architecture
SPS: 3221, pg_loss=0.0751, v_loss=0.3995
Epoch: 654, global_step=66867200
Sampling new architecture
SPS: 3224, pg_loss=0.0215, v_loss=0.3465
Epoch: 655, global_step=66969600
Sampling new architecture
SPS: 3227, pg_loss=0.0482, v_loss=0.3911
Epoch: 656, global_step=67072000
Sampling new architecture
SPS: 3230, pg_loss=0.0679, v_loss=0.4234
Epoch: 657, global_step=67174400
Sampling new architecture
SPS: 3233, pg_loss=0.0745, v_loss=0.4031
Epoch: 658, global_step=67276800
Sampling new architecture
SPS: 3236, pg_loss=0.0267, v_loss=0.4414
Epoch: 659, global_step=67379200
Sampling new architecture
SPS: 3239, pg_loss=0.0281, v_loss=0.3067
Epoch: 660, global_step=67481600
Sampling new architecture
SPS: 3243, pg_loss=0.0485, v_loss=0.4290
Epoch: 661, global_step=67584000
Sampling new architecture
SPS: 3246, pg_loss=0.0312, v_loss=0.3773
Epoch: 662, global_step=67686400
Sampling new architecture
SPS: 3249, pg_loss=0.0504, v_loss=0.3295
Epoch: 663, global_step=67788800
Sampling new architecture
SPS: 3252, pg_loss=0.0409, v_loss=0.3736
Epoch: 664, global_step=67891200
Sampling new architecture
SPS: 3255, pg_loss=0.0664, v_loss=0.4014
Epoch: 665, global_step=67993600
Sampling new architecture
SPS: 3254, pg_loss=0.0445, v_loss=0.2866
Epoch: 666, global_step=68096000
Sampling new architecture
SPS: 3257, pg_loss=0.0426, v_loss=0.3303
Epoch: 667, global_step=68198400
Sampling new architecture
SPS: 3260, pg_loss=0.0379, v_loss=0.3063
Epoch: 668, global_step=68300800
Sampling new architecture
SPS: 3263, pg_loss=0.0441, v_loss=0.3392
Epoch: 669, global_step=68403200
Sampling new architecture
SPS: 3262, pg_loss=0.0331, v_loss=0.2371
Epoch: 670, global_step=68505600
Sampling new architecture
SPS: 3261, pg_loss=0.0515, v_loss=0.2561
Epoch: 671, global_step=68608000
Sampling new architecture
SPS: 3261, pg_loss=0.0557, v_loss=0.2435
Epoch: 672, global_step=68710400
Sampling new architecture
SPS: 3260, pg_loss=0.0564, v_loss=0.1960
Epoch: 673, global_step=68812800
Sampling new architecture
SPS: 3259, pg_loss=0.0729, v_loss=0.2142
Epoch: 674, global_step=68915200
Sampling new architecture
SPS: 3258, pg_loss=0.0639, v_loss=0.2040
Epoch: 675, global_step=69017600
Sampling new architecture
SPS: 3257, pg_loss=0.0643, v_loss=0.2269
Epoch: 676, global_step=69120000
Sampling new architecture
SPS: 3257, pg_loss=0.0429, v_loss=0.2175
Epoch: 677, global_step=69222400
Sampling new architecture
SPS: 3256, pg_loss=0.0380, v_loss=0.1941
Epoch: 678, global_step=69324800
Sampling new architecture
SPS: 3255, pg_loss=0.0418, v_loss=0.1832
Epoch: 679, global_step=69427200
Sampling new architecture
SPS: 3254, pg_loss=0.0338, v_loss=0.2113
Epoch: 680, global_step=69529600
Sampling new architecture
SPS: 3253, pg_loss=0.0489, v_loss=0.2073
Epoch: 681, global_step=69632000
Sampling new architecture
SPS: 3254, pg_loss=0.0498, v_loss=0.2146
Epoch: 682, global_step=69734400
Sampling new architecture
SPS: 3253, pg_loss=0.0537, v_loss=0.2183
Epoch: 683, global_step=69836800
Sampling new architecture
SPS: 3252, pg_loss=0.0627, v_loss=0.1890
Epoch: 684, global_step=69939200
Sampling new architecture
SPS: 3252, pg_loss=0.0609, v_loss=0.2367
Epoch: 685, global_step=70041600
Sampling new architecture
SPS: 3251, pg_loss=0.0625, v_loss=0.1974
Epoch: 686, global_step=70144000
Sampling new architecture
SPS: 3249, pg_loss=0.0169, v_loss=0.2052
Epoch: 687, global_step=70246400
Sampling new architecture
SPS: 3248, pg_loss=0.0473, v_loss=0.1986
Epoch: 688, global_step=70348800
Sampling new architecture
SPS: 3247, pg_loss=0.0523, v_loss=0.1820
Epoch: 689, global_step=70451200
Sampling new architecture
SPS: 3247, pg_loss=0.0470, v_loss=0.2170
Epoch: 690, global_step=70553600
Sampling new architecture
SPS: 3250, pg_loss=0.0557, v_loss=0.2544
Epoch: 691, global_step=70656000
Sampling new architecture
SPS: 3249, pg_loss=0.0351, v_loss=0.1937
Epoch: 692, global_step=70758400
Sampling new architecture
SPS: 3252, pg_loss=0.0736, v_loss=0.2417
Epoch: 693, global_step=70860800
Sampling new architecture
SPS: 3251, pg_loss=0.0629, v_loss=0.2171
Epoch: 694, global_step=70963200
Sampling new architecture
SPS: 3250, pg_loss=0.0614, v_loss=0.2079
Epoch: 695, global_step=71065600
Sampling new architecture
SPS: 3249, pg_loss=0.0395, v_loss=0.1779
Epoch: 696, global_step=71168000
Sampling new architecture
SPS: 3250, pg_loss=0.0501, v_loss=0.1877
Epoch: 697, global_step=71270400
Sampling new architecture
SPS: 3250, pg_loss=0.0628, v_loss=0.1735
Epoch: 698, global_step=71372800
Sampling new architecture
SPS: 3249, pg_loss=0.0506, v_loss=0.1647
Epoch: 699, global_step=71475200
Sampling new architecture
SPS: 3247, pg_loss=0.0320, v_loss=0.1695
Epoch: 700, global_step=71577600
Sampling new architecture
SPS: 3247, pg_loss=0.0605, v_loss=0.1562
Epoch: 701, global_step=71680000
Sampling new architecture
Evaluating
Initializing ContextualPandaStick...
Initializing ContextualPandaStick...
Evaluated 400 steps resulting in 8 episodes
Total reward during evaluation: 28.471178710460663
eval_success_once_mean=0.0
eval_return_mean=3.558897018432617
eval_episode_len_mean=50.0
eval_reward_mean=0.07117793709039688
eval_success_at_end_mean=0.0
model saved to runs/ContextualPushT-v1__Contextual_hyperppo__1__1747283748/ckpt_701.pt
SPS: 3245, pg_loss=0.0474, v_loss=0.1665
Epoch: 702, global_step=71782400
Sampling new architecture
SPS: 3243, pg_loss=0.0386, v_loss=0.1568
Epoch: 703, global_step=71884800
Sampling new architecture
SPS: 3243, pg_loss=0.0797, v_loss=0.1731
Epoch: 704, global_step=71987200
Sampling new architecture
SPS: 3242, pg_loss=0.0442, v_loss=0.1474
Epoch: 705, global_step=72089600
Sampling new architecture
SPS: 3244, pg_loss=0.0481, v_loss=0.2332
Epoch: 706, global_step=72192000
Sampling new architecture
SPS: 3246, pg_loss=0.1141, v_loss=0.2207
Epoch: 707, global_step=72294400
Sampling new architecture
SPS: 3249, pg_loss=0.0632, v_loss=0.2635
Epoch: 708, global_step=72396800
Sampling new architecture
SPS: 3249, pg_loss=0.0637, v_loss=0.1658
Epoch: 709, global_step=72499200
Sampling new architecture
SPS: 3250, pg_loss=0.0422, v_loss=0.1643
Epoch: 710, global_step=72601600
Sampling new architecture
SPS: 3249, pg_loss=0.0350, v_loss=0.1403
Epoch: 711, global_step=72704000
Sampling new architecture
SPS: 3249, pg_loss=0.0570, v_loss=0.1511
Epoch: 712, global_step=72806400
Sampling new architecture
SPS: 3251, pg_loss=0.0590, v_loss=0.1907
Epoch: 713, global_step=72908800
Sampling new architecture
SPS: 3254, pg_loss=0.1112, v_loss=0.2598
Epoch: 714, global_step=73011200
Sampling new architecture
SPS: 3255, pg_loss=0.0435, v_loss=0.1898
Epoch: 715, global_step=73113600
Sampling new architecture
SPS: 3255, pg_loss=0.0415, v_loss=0.1774
Epoch: 716, global_step=73216000
Sampling new architecture
SPS: 3254, pg_loss=0.0674, v_loss=0.1667
Epoch: 717, global_step=73318400
Sampling new architecture
SPS: 3253, pg_loss=0.0236, v_loss=0.1794
Epoch: 718, global_step=73420800
Sampling new architecture
SPS: 3256, pg_loss=0.0566, v_loss=0.1798
Epoch: 719, global_step=73523200
Sampling new architecture
SPS: 3255, pg_loss=0.0491, v_loss=0.1453
Epoch: 720, global_step=73625600
Sampling new architecture
SPS: 3258, pg_loss=0.0522, v_loss=0.1701
Epoch: 721, global_step=73728000
Sampling new architecture
SPS: 3261, pg_loss=0.0658, v_loss=0.1746
Epoch: 722, global_step=73830400
Sampling new architecture
SPS: 3260, pg_loss=0.0382, v_loss=0.1858
Epoch: 723, global_step=73932800
Sampling new architecture
SPS: 3263, pg_loss=0.0435, v_loss=0.2456
Epoch: 724, global_step=74035200
Sampling new architecture
SPS: 3263, pg_loss=0.0324, v_loss=0.1780
Epoch: 725, global_step=74137600
Sampling new architecture
SPS: 3266, pg_loss=0.0781, v_loss=0.1979
Epoch: 726, global_step=74240000
Sampling new architecture
SPS: 3269, pg_loss=0.0451, v_loss=0.2288
Epoch: 727, global_step=74342400
Sampling new architecture
SPS: 3267, pg_loss=0.0318, v_loss=0.1786
Epoch: 728, global_step=74444800
Sampling new architecture
SPS: 3267, pg_loss=0.0593, v_loss=0.1843
Epoch: 729, global_step=74547200
Sampling new architecture
SPS: 3266, pg_loss=0.0419, v_loss=0.1635
Epoch: 730, global_step=74649600
Sampling new architecture
SPS: 3269, pg_loss=0.0361, v_loss=0.2017
Epoch: 731, global_step=74752000
Sampling new architecture
SPS: 3272, pg_loss=0.0598, v_loss=0.2631
Epoch: 732, global_step=74854400
Sampling new architecture
SPS: 3275, pg_loss=0.0482, v_loss=0.2426
Epoch: 733, global_step=74956800
Sampling new architecture
SPS: 3278, pg_loss=0.0526, v_loss=0.2357
Epoch: 734, global_step=75059200
Sampling new architecture
SPS: 3277, pg_loss=0.0405, v_loss=0.2228
Epoch: 735, global_step=75161600
Sampling new architecture
SPS: 3276, pg_loss=0.0431, v_loss=0.1587
Epoch: 736, global_step=75264000
Sampling new architecture
SPS: 3278, pg_loss=0.0547, v_loss=0.2634
Epoch: 737, global_step=75366400
Sampling new architecture
SPS: 3279, pg_loss=0.0413, v_loss=0.2346
Epoch: 738, global_step=75468800
Sampling new architecture
SPS: 3279, pg_loss=0.0434, v_loss=0.2107
Epoch: 739, global_step=75571200
Sampling new architecture
SPS: 3281, pg_loss=0.0601, v_loss=0.2362
Epoch: 740, global_step=75673600
Sampling new architecture
SPS: 3284, pg_loss=0.0370, v_loss=0.3671
Epoch: 741, global_step=75776000
Sampling new architecture
SPS: 3287, pg_loss=0.1006, v_loss=0.3062
Epoch: 742, global_step=75878400
Sampling new architecture
SPS: 3289, pg_loss=0.0487, v_loss=0.2131
Epoch: 743, global_step=75980800
Sampling new architecture
SPS: 3292, pg_loss=0.0590, v_loss=0.3194
Epoch: 744, global_step=76083200
Sampling new architecture
SPS: 3295, pg_loss=0.0519, v_loss=0.2170
Epoch: 745, global_step=76185600
Sampling new architecture
SPS: 3297, pg_loss=0.0443, v_loss=0.1928
Epoch: 746, global_step=76288000
Sampling new architecture
SPS: 3300, pg_loss=0.0516, v_loss=0.2374
Epoch: 747, global_step=76390400
Sampling new architecture
SPS: 3303, pg_loss=0.0579, v_loss=0.3214
Epoch: 748, global_step=76492800
Sampling new architecture
SPS: 3305, pg_loss=0.0495, v_loss=0.3694
Epoch: 749, global_step=76595200
Sampling new architecture
SPS: 3307, pg_loss=0.0349, v_loss=0.2231
Epoch: 750, global_step=76697600
Sampling new architecture
SPS: 3310, pg_loss=0.0654, v_loss=0.2182
Epoch: 751, global_step=76800000
Sampling new architecture
Evaluating
Initializing ContextualPandaStick...
Initializing ContextualPandaStick...
Evaluated 400 steps resulting in 8 episodes
Total reward during evaluation: 55.70016264915466
eval_success_once_mean=0.0
eval_return_mean=6.962520122528076
eval_episode_len_mean=50.0
eval_reward_mean=0.13925039768218994
eval_success_at_end_mean=0.0
model saved to runs/ContextualPushT-v1__Contextual_hyperppo__1__1747283748/ckpt_751.pt
SPS: 3308, pg_loss=0.0485, v_loss=0.2081
Epoch: 752, global_step=76902400
Sampling new architecture
SPS: 3308, pg_loss=0.0803, v_loss=0.2334
Epoch: 753, global_step=77004800
Sampling new architecture
SPS: 3309, pg_loss=0.0561, v_loss=0.1924
Epoch: 754, global_step=77107200
Sampling new architecture
SPS: 3308, pg_loss=0.0517, v_loss=0.1827
Epoch: 755, global_step=77209600
Sampling new architecture
SPS: 3311, pg_loss=0.1106, v_loss=0.1986
Epoch: 756, global_step=77312000
Sampling new architecture
SPS: 3313, pg_loss=0.0700, v_loss=0.2258
Epoch: 757, global_step=77414400
Sampling new architecture
SPS: 3312, pg_loss=0.0240, v_loss=0.2016
Epoch: 758, global_step=77516800
Sampling new architecture
SPS: 3313, pg_loss=0.0691, v_loss=0.1530
Epoch: 759, global_step=77619200
Sampling new architecture
SPS: 3312, pg_loss=0.0660, v_loss=0.1526
Epoch: 760, global_step=77721600
Sampling new architecture
SPS: 3311, pg_loss=0.0592, v_loss=0.1538
Epoch: 761, global_step=77824000
Sampling new architecture
SPS: 3310, pg_loss=0.0529, v_loss=0.1680
Epoch: 762, global_step=77926400
Sampling new architecture
SPS: 3309, pg_loss=0.0574, v_loss=0.1790
Epoch: 763, global_step=78028800
Sampling new architecture
SPS: 3312, pg_loss=0.0707, v_loss=0.2693
Epoch: 764, global_step=78131200
Sampling new architecture
SPS: 3311, pg_loss=0.0716, v_loss=0.1649
Epoch: 765, global_step=78233600
Sampling new architecture
SPS: 3310, pg_loss=0.0681, v_loss=0.1516
Epoch: 766, global_step=78336000
Sampling new architecture
SPS: 3309, pg_loss=0.0307, v_loss=0.1936
Epoch: 767, global_step=78438400
Sampling new architecture
SPS: 3308, pg_loss=0.0571, v_loss=0.1658
Epoch: 768, global_step=78540800
Sampling new architecture
SPS: 3307, pg_loss=0.0553, v_loss=0.1597
Epoch: 769, global_step=78643200
Sampling new architecture
SPS: 3306, pg_loss=0.0317, v_loss=0.1432
Epoch: 770, global_step=78745600
Sampling new architecture
SPS: 3305, pg_loss=0.0331, v_loss=0.1478
Epoch: 771, global_step=78848000
Sampling new architecture
SPS: 3304, pg_loss=0.0411, v_loss=0.1626
Epoch: 772, global_step=78950400
Sampling new architecture
SPS: 3303, pg_loss=0.0491, v_loss=0.1369
Epoch: 773, global_step=79052800
Sampling new architecture
SPS: 3303, pg_loss=0.0417, v_loss=0.1231
Epoch: 774, global_step=79155200
Sampling new architecture
SPS: 3301, pg_loss=0.0263, v_loss=0.1665
Epoch: 775, global_step=79257600
Sampling new architecture
SPS: 3300, pg_loss=0.0469, v_loss=0.1261
Epoch: 776, global_step=79360000
Sampling new architecture
SPS: 3300, pg_loss=0.0409, v_loss=0.1377
Epoch: 777, global_step=79462400
Sampling new architecture
SPS: 3299, pg_loss=0.0469, v_loss=0.1342
Epoch: 778, global_step=79564800
Sampling new architecture
SPS: 3298, pg_loss=0.0229, v_loss=0.1566
Epoch: 779, global_step=79667200
Sampling new architecture
SPS: 3300, pg_loss=0.0730, v_loss=0.2265
Epoch: 780, global_step=79769600
Sampling new architecture
SPS: 3299, pg_loss=0.0602, v_loss=0.1317
Epoch: 781, global_step=79872000
Sampling new architecture
SPS: 3299, pg_loss=0.0698, v_loss=0.1337
Epoch: 782, global_step=79974400
Sampling new architecture
SPS: 3298, pg_loss=0.0479, v_loss=0.1228
Epoch: 783, global_step=80076800
Sampling new architecture
SPS: 3298, pg_loss=0.0687, v_loss=0.1127
Epoch: 784, global_step=80179200
Sampling new architecture
SPS: 3300, pg_loss=0.0624, v_loss=0.1717
Epoch: 785, global_step=80281600
Sampling new architecture
SPS: 3299, pg_loss=0.0306, v_loss=0.1406
Epoch: 786, global_step=80384000
Sampling new architecture
SPS: 3299, pg_loss=0.0474, v_loss=0.1362
Epoch: 787, global_step=80486400
Sampling new architecture
SPS: 3298, pg_loss=0.0401, v_loss=0.1308
Epoch: 788, global_step=80588800
Sampling new architecture
SPS: 3297, pg_loss=0.0418, v_loss=0.1222
Epoch: 789, global_step=80691200
Sampling new architecture
SPS: 3296, pg_loss=0.0472, v_loss=0.1367
Epoch: 790, global_step=80793600
Sampling new architecture
SPS: 3295, pg_loss=0.0434, v_loss=0.1502
Epoch: 791, global_step=80896000
Sampling new architecture
SPS: 3297, pg_loss=0.0709, v_loss=0.1641
Epoch: 792, global_step=80998400
Sampling new architecture
SPS: 3296, pg_loss=0.0445, v_loss=0.1715
Epoch: 793, global_step=81100800
Sampling new architecture
SPS: 3298, pg_loss=0.0595, v_loss=0.1927
Epoch: 794, global_step=81203200
Sampling new architecture
SPS: 3298, pg_loss=0.0617, v_loss=0.1342
Epoch: 795, global_step=81305600
Sampling new architecture
SPS: 3297, pg_loss=0.0677, v_loss=0.1436
Epoch: 796, global_step=81408000
Sampling new architecture
SPS: 3297, pg_loss=0.0644, v_loss=0.1499
Epoch: 797, global_step=81510400
Sampling new architecture
SPS: 3296, pg_loss=0.0396, v_loss=0.1497
Epoch: 798, global_step=81612800
Sampling new architecture
SPS: 3295, pg_loss=0.0624, v_loss=0.1320
Epoch: 799, global_step=81715200
Sampling new architecture
SPS: 3294, pg_loss=0.0450, v_loss=0.1632
Epoch: 800, global_step=81817600
Sampling new architecture
SPS: 3297, pg_loss=0.0363, v_loss=0.1777
Epoch: 801, global_step=81920000
Sampling new architecture
Evaluating
Initializing ContextualPandaStick...
Initializing ContextualPandaStick...
Evaluated 400 steps resulting in 8 episodes
Total reward during evaluation: 47.963762521743774
eval_success_once_mean=0.0
eval_return_mean=5.9954705238342285
eval_episode_len_mean=50.0
eval_reward_mean=0.11990940570831299
eval_success_at_end_mean=0.0
model saved to runs/ContextualPushT-v1__Contextual_hyperppo__1__1747283748/ckpt_801.pt
SPS: 3298, pg_loss=0.0604, v_loss=0.1916
Epoch: 802, global_step=82022400
Sampling new architecture
SPS: 3297, pg_loss=0.0542, v_loss=0.1646
Epoch: 803, global_step=82124800
Sampling new architecture
SPS: 3296, pg_loss=0.0295, v_loss=0.1518
Epoch: 804, global_step=82227200
Sampling new architecture
SPS: 3298, pg_loss=0.0473, v_loss=0.2069
Epoch: 805, global_step=82329600
Sampling new architecture
SPS: 3298, pg_loss=0.0455, v_loss=0.1731
Epoch: 806, global_step=82432000
Sampling new architecture
SPS: 3300, pg_loss=0.0728, v_loss=0.2234
Epoch: 807, global_step=82534400
Sampling new architecture
SPS: 3302, pg_loss=0.0442, v_loss=0.1863
Epoch: 808, global_step=82636800
Sampling new architecture
SPS: 3305, pg_loss=0.0522, v_loss=0.2026
Epoch: 809, global_step=82739200
Sampling new architecture
SPS: 3304, pg_loss=0.0647, v_loss=0.1667
Epoch: 810, global_step=82841600
Sampling new architecture
SPS: 3307, pg_loss=0.0608, v_loss=0.1841
Epoch: 811, global_step=82944000
Sampling new architecture
SPS: 3309, pg_loss=0.0588, v_loss=0.2123
Epoch: 812, global_step=83046400
Sampling new architecture
SPS: 3311, pg_loss=0.0408, v_loss=0.1964
Epoch: 813, global_step=83148800
Sampling new architecture
SPS: 3314, pg_loss=0.0407, v_loss=0.2145
Epoch: 814, global_step=83251200
Sampling new architecture
SPS: 3315, pg_loss=0.0487, v_loss=0.1774
Epoch: 815, global_step=83353600
Sampling new architecture
SPS: 3315, pg_loss=0.0564, v_loss=0.1764
Epoch: 816, global_step=83456000
Sampling new architecture
SPS: 3314, pg_loss=0.0333, v_loss=0.1527
Epoch: 817, global_step=83558400
Sampling new architecture
SPS: 3313, pg_loss=0.0306, v_loss=0.1470
Epoch: 818, global_step=83660800
Sampling new architecture
SPS: 3312, pg_loss=0.0480, v_loss=0.1634
Epoch: 819, global_step=83763200
Sampling new architecture
SPS: 3311, pg_loss=0.0389, v_loss=0.1421
Epoch: 820, global_step=83865600
Sampling new architecture
SPS: 3310, pg_loss=0.0431, v_loss=0.1347
Epoch: 821, global_step=83968000
Sampling new architecture
SPS: 3309, pg_loss=0.0323, v_loss=0.1556
Epoch: 822, global_step=84070400
Sampling new architecture
SPS: 3308, pg_loss=0.0342, v_loss=0.1240
Epoch: 823, global_step=84172800
Sampling new architecture
SPS: 3307, pg_loss=0.0829, v_loss=0.1090
Epoch: 824, global_step=84275200
Sampling new architecture
SPS: 3306, pg_loss=0.0610, v_loss=0.0976
Epoch: 825, global_step=84377600
Sampling new architecture
SPS: 3306, pg_loss=0.0333, v_loss=0.1018
Epoch: 826, global_step=84480000
Sampling new architecture
SPS: 3305, pg_loss=0.0317, v_loss=0.1242
Epoch: 827, global_step=84582400
Sampling new architecture
SPS: 3304, pg_loss=0.0269, v_loss=0.1145
Epoch: 828, global_step=84684800
Sampling new architecture
SPS: 3303, pg_loss=0.0454, v_loss=0.1104
Epoch: 829, global_step=84787200
Sampling new architecture
SPS: 3302, pg_loss=0.0342, v_loss=0.1168
Epoch: 830, global_step=84889600
Sampling new architecture
SPS: 3301, pg_loss=0.0323, v_loss=0.1191
Epoch: 831, global_step=84992000
Sampling new architecture
SPS: 3300, pg_loss=0.0287, v_loss=0.1244
Epoch: 832, global_step=85094400
Sampling new architecture
SPS: 3299, pg_loss=0.0253, v_loss=0.1160
Epoch: 833, global_step=85196800
Sampling new architecture
SPS: 3299, pg_loss=0.0444, v_loss=0.0918
Epoch: 834, global_step=85299200
Sampling new architecture
Traceback (most recent call last):
  File "/home/swarajh/ContextualManiskill/Contextual_hyperppo.py", line 557, in <module>
    _, new_logprob, entropy, new_value = agent.get_action_and_value(obs_batch, act_batch)
  File "/home/swarajh/ContextualManiskill/Contextual_hyperppo.py", line 205, in get_action_and_value
    dist = Normal(mu, std)
  File "/home/swarajh/miniconda3/envs/hyper/lib/python3.9/site-packages/torch/distributions/normal.py", line 59, in __init__
    super().__init__(batch_shape, validate_args=validate_args)
  File "/home/swarajh/miniconda3/envs/hyper/lib/python3.9/site-packages/torch/distributions/distribution.py", line 71, in __init__
    raise ValueError(
ValueError: Expected parameter loc (Tensor of shape (3200, 7)) of distribution Normal(loc: torch.Size([3200, 7]), scale: torch.Size([3200, 7])) to satisfy the constraint Real(), but found invalid values:
tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       grad_fn=<CatBackward0>)
